{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2.4: Advanced Workflows\n",
    "\n",
    "| **Aspect** | **Details** |\n",
    "|-------------|-------------|\n",
    "| **Goal** | Master prompt chaining patterns for complex workflows. |\n",
    "| **Time** | ~20 minutes |\n",
    "| **Prerequisites** | Complete Sections 2.1‚Äì2.3 and understand reasoning patterns. |\n",
    "| **Next Steps** | Continue to Section 2.5: Hands-On Practice |\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Setup Check\n",
    "\n",
    "Since you completed Sections 2.1-2.3, setup is already done. Import it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick setup check - imports setup_utils\n",
    "try:\n",
    "    import importlib\n",
    "    import setup_utils\n",
    "    importlib.reload(setup_utils)\n",
    "    from setup_utils import *\n",
    "    print(f\"Setup loaded. Using {AVAILABLE_PROVIDERS} with {get_default_model()}\")\n",
    "    print(\"Ready to continue.\")\n",
    "except ImportError:\n",
    "    print(\"Setup not found.\")\n",
    "    print(\"Please run 2.1-setup-and-foundations.ipynb first to set up your environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Tactic 6: Prompt Chaining\n",
    "\n",
    "Break complex tasks into sequential, focused steps.\n",
    "\n",
    "Complex tasks cause AI to lose focus. Chaining breaks work into steps where each gets full attention.\n",
    "\n",
    "**Single prompt:** \"Review code for security, performance, and style, then fix everything and write tests\"\n",
    "- AI juggles too much at once\n",
    "- Shallow analysis on each aspect\n",
    "- Fixes generated without deep understanding\n",
    "\n",
    "**Chained approach:** Break into focused steps where each builds on the previous\n",
    "\n",
    "**Core pattern:**\n",
    "```python\n",
    "# Step 1\n",
    "result_1 = ai(\"First focused task\")\n",
    "\n",
    "# Step 2 uses Step 1 output\n",
    "result_2 = ai(f\"Second task using: {result_1}\")\n",
    "\n",
    "# Step 3 uses Step 2 output  \n",
    "result_3 = ai(f\"Third task using: {result_2}\")\n",
    "```\n",
    "\n",
    "**When This Matters for Engineers:**\n",
    "\n",
    "Claude Code, GitHub Copilot, Cursor, and OpenAI Codex use prompt chaining internally for complex tasks. When you ask \"review and fix this code,\" they often chain steps automatically: analyze ‚Üí fix ‚Üí verify.\n",
    "\n",
    "- **Building custom workflows:** Writing agent skills, CI/CD automation, code review bots\n",
    "- **Debugging tool behavior:** Understanding why Claude Code broke a task into multiple steps\n",
    "- **Optimizing results:** Manually chaining when automatic chaining isn't sufficient\n",
    "- **Direct API usage:** Calling OpenAI, Anthropic, or Circuit APIs programmatically\n",
    "\n",
    "**Industry Standard Patterns:**\n",
    "\n",
    "Production frameworks like [LangChain](https://docs.langchain.com/oss/python/langchain/overview) formalize these patterns for building AI workflows and agents:\n",
    "\n",
    "- **Workflows:** Predetermined code paths with defined execution order (what we're teaching here)\n",
    "- **Agents:** Dynamic systems that choose their own tools and approaches\n",
    "- **Common patterns:** Sequential chaining, parallelization, routing, orchestrator-worker, evaluator-optimizer\n",
    "\n",
    "The patterns you'll learn here align with these production frameworks. For implementation details, see [LangGraph workflows documentation](https://docs.langchain.com/oss/python/langgraph/workflows-agents).\n",
    "\n",
    "**Three common chaining patterns:**\n",
    "\n",
    "1. **Sequential Workflow:** Linear steps with different focuses (analyze ‚Üí fix ‚Üí test)\n",
    "2. **Self-Correction:** Generate ‚Üí critique own work ‚Üí improve (role switching)\n",
    "3. **Parallel Exploration:** Generate multiple options ‚Üí evaluate ‚Üí select best\n",
    "\n",
    "All three are variations of chaining. Use XML tags (`<analysis>`, `<code>`, `<options>`) to pass data between steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pattern 1: Sequential Workflow\n",
    "\n",
    "Each step has a different focus. Output from one step becomes input to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared setup helpers (run Section 2.1 first to install dependencies)\n",
    "from setup_utils import get_chat_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vulnerable code example\n",
    "code = \"\"\"\n",
    "def login(username, password):\n",
    "    query = f\"SELECT * FROM users WHERE user='{username}' AND pass='{password}'\"\n",
    "    result = db.execute(query)\n",
    "    return result\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 1: Security Analysis\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Step 1: Focused security analysis\n",
    "analysis = get_chat_completion([{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": f\"\"\"Analyze security vulnerabilities in this code:\n",
    "\n",
    "{code}\n",
    "\n",
    "List specific issues with severity (CRITICAL/HIGH/MEDIUM/LOW).\"\"\"\n",
    "}])\n",
    "\n",
    "print(analysis)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 2: Generate Secure Fix\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Step 2: Fix based on analysis\n",
    "fix = get_chat_completion([{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": f\"\"\"Security issues found:\n",
    "{analysis}\n",
    "\n",
    "Original code:\n",
    "{code}\n",
    "\n",
    "Provide fixed code with:\n",
    "- Parameterized queries\n",
    "- Input validation  \n",
    "- Error handling\n",
    "\n",
    "Wrap code in <code></code> tags.\"\"\"\n",
    "}])\n",
    "\n",
    "print(fix)\n",
    "\n",
    "print(\"\\nüí° Each step focused on one thing. Step 2 had full context from Step 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pattern 2: Self-Correction\n",
    "\n",
    "AI generates, then critiques its own work, then improves it. Role switching from creator to critic.\n",
    "\n",
    "```\n",
    "Generate ‚Üí Critique own work ‚Üí Fix issues\n",
    "```\n",
    "\n",
    "This combines chaining with role switching and weighted criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def extract_between_tags(text, tag):\n",
    "    start = f\"<{tag}>\"\n",
    "    end = f\"</{tag}>\"\n",
    "    if start in text and end in text:\n",
    "        return text[text.find(start) + len(start):text.find(end)].strip()\n",
    "    return text\n",
    "\n",
    "# Step 1: Generate\n",
    "print(\"Step 1: Generate password validator...\")\n",
    "draft = get_chat_completion([{\"role\": \"user\", \"content\": \"Create Python function to validate password strength. Wrap in <code> tags.\"}])\n",
    "code = extract_between_tags(draft, \"code\")\n",
    "print(f\"Generated {len(code)} characters of code\")\n",
    "print(code)\n",
    "print()\n",
    "\n",
    "# Step 2: Critique with weighted criteria\n",
    "print(\"Step 2: AI reviews its own code (role switch to critic)...\")\n",
    "critique = get_chat_completion([{\"role\": \"system\", \"content\": \"You are a security-focused code reviewer.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"\"\"Review this code:\n",
    "{code}\n",
    "\n",
    "Weighted scoring:\n",
    "- Security (50%): Weak password risks, timing attacks\n",
    "- Validation (30%): Length, complexity checks  \n",
    "- Usability (20%): Error messages, feedback\n",
    "\n",
    "For each:\n",
    "- Score 0-10\n",
    "- List issues\n",
    "- Severity: CRITICAL/HIGH/MEDIUM/LOW\n",
    "\n",
    "Format: <issues>[list]</issues>\"\"\"}])\n",
    "\n",
    "issues = extract_between_tags(critique, \"issues\")\n",
    "print(f\"Issues found:\")\n",
    "print(issues)\n",
    "print()\n",
    "\n",
    "# Step 3: Self-improve\n",
    "print(\"Step 3: AI fixes identified issues...\")\n",
    "improved = get_chat_completion([{\"role\": \"user\", \"content\": f\"\"\"Original:\n",
    "{code}\n",
    "\n",
    "Issues:\n",
    "{issues}\n",
    "\n",
    "Fix all CRITICAL and HIGH issues. Keep changes minimal. Wrap in <improved> tags.\"\"\"}])\n",
    "final_code = extract_between_tags(improved, \"improved\")\n",
    "print(f\"‚úÖ Improved version ({len(final_code)} characters)\")\n",
    "print(final_code)\n",
    "\n",
    "print(\"\\nüí° Self-correction catches mistakes automatically before human review.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key Takeaways: Prompt Chaining\n",
    "\n",
    "**Best Practices Demonstrated:**\n",
    "1. **One focus per step:** Each prompt has a single, clear objective\n",
    "2. **Sequential dependencies:** Later steps use earlier outputs as input\n",
    "3. **XML structure:** Tags like `<analysis>`, `<code>`, `<issues>` pass data cleanly\n",
    "4. **Role switching:** AI can act as creator (Step 1) then critic (Step 2)\n",
    "5. **Weighted criteria:** Prioritize what matters (security bugs > missing docs)\n",
    "\n",
    "**Common chaining patterns:**\n",
    "- **Sequential workflow:** Step 1 ‚Üí Step 2 ‚Üí Step 3 (each builds on previous)\n",
    "- **Self-improvement:** Generate ‚Üí Critique ‚Üí Fix (role switch between steps)\n",
    "- **Iterative refinement:** Generate ‚Üí Critique ‚Üí Fix ‚Üí Verify ‚Üí Fix again\n",
    "\n",
    "**When to use:**\n",
    "- Multi-step workflows (analyze ‚Üí fix ‚Üí test)\n",
    "- Quality-critical tasks (code reviews, security audits)\n",
    "- Complex refactoring with verification steps\n",
    "\n",
    "**When NOT to use:**\n",
    "- Simple, single-step tasks\n",
    "- Speed matters more than quality\n",
    "- No intermediate verification needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Try It Yourself: Prompt Chaining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Common Misconception:** AI can handle multiple complex tasks in one prompt as well as breaking them into steps.\n",
    "\n",
    "**The Reality:** Chaining gives each task full attention, dramatically improving quality.\n",
    "\n",
    "**Your Task:** Compare single prompt vs chained approach. First run the BAD example, then uncomment the GOOD chained version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vulnerable_code = \"\"\"\n",
    "def process_payment(amount, card):\n",
    "    if amount > 0:\n",
    "        charge(card, amount)\n",
    "        return \"success\"\n",
    "\"\"\"\n",
    "\n",
    "# ‚ùå BAD: Everything at once\n",
    "print(\"Single Prompt: Do everything at once\")\n",
    "single = get_chat_completion([{\"role\": \"user\", \"content\": f\"Review, fix, and test this code:\\n{vulnerable_code}\"}])\n",
    "print(single)\n",
    "print()\n",
    "\n",
    "# ‚úÖ YOUR TURN: Uncomment to try chained approach\n",
    "# print(\"\\nChained: Three focused steps\")\n",
    "# \n",
    "# # Step 1: Just analyze\n",
    "# analysis = get_chat_completion([{\"role\": \"user\", \"content\": f\"List security and validation issues:\\n{vulnerable_code}\"}])\n",
    "# print(f\"Step 1 - Analysis:\\n{analysis}\\n\")\n",
    "# \n",
    "# # Step 2: Just fix\n",
    "# fixed = get_chat_completion([{\"role\": \"user\", \"content\": f\"Fix issues:\\n{analysis}\\n\\nCode:\\n{vulnerable_code}\"}])\n",
    "# print(f\"Step 2 - Fixed Code:\\n{fixed}\\n\")\n",
    "# \n",
    "# # Step 3: Just test\n",
    "# tests = get_chat_completion([{\"role\": \"user\", \"content\": f\"Write tests for:\\n{fixed}\"}])\n",
    "# print(f\"Step 3 - Tests:\\n{tests}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Pattern 3: Parallel Exploration\n",
    "\n",
    "Generate multiple approaches simultaneously, then evaluate and pick the best one.\n",
    "\n",
    "**The idea:** Instead of asking for one approach, generate several at the same time. Compare them, then choose.\n",
    "\n",
    "**Why parallel?**\n",
    "- **Sequential:** Ask for approach A ‚Üí wait ‚Üí ask for approach B ‚Üí wait ‚Üí ask for approach C (slow)\n",
    "- **Parallel:** Ask for A, B, and C all at once ‚Üí wait once ‚Üí get all three (fast)\n",
    "\n",
    "You'll see this in action below. Parallel execution typically runs 3-5x faster.\n",
    "\n",
    "**When this helps:**\n",
    "- Choosing between algorithms or data structures\n",
    "- Picking libraries or frameworks\n",
    "- Architecture decisions where multiple options exist\n",
    "- Any time you need to compare trade-offs\n",
    "\n",
    "**Skip it when:**\n",
    "- There's a clear best practice already\n",
    "- You're rate-limited by the API\n",
    "- Speed isn't important\n",
    "\n",
    "**How it works:**\n",
    "\n",
    "<div style=\"margin: 20px 0; padding: 20px; background: #f8fafc; border-radius: 8px; font-family: monospace; font-size: 13px;\">\n",
    "  <div style=\"text-align: center; margin-bottom: 15px;\">\n",
    "    <div style=\"background: #fee2e2; padding: 8px 16px; border-radius: 6px; display: inline-block; color: #991b1b; font-weight: 600;\">User Query</div>\n",
    "  </div>\n",
    "  <div style=\"text-align: center; margin-bottom: 15px;\">\n",
    "    <div style=\"font-size: 20px; color: #64748b;\">‚Üì</div>\n",
    "  </div>\n",
    "  <div style=\"text-align: center; margin-bottom: 15px;\">\n",
    "    <div style=\"background: #e0e7ff; padding: 12px 20px; border-radius: 6px; display: inline-block; color: #3730a3; font-weight: 600;\">Generate 3 approaches simultaneously</div>\n",
    "  </div>\n",
    "  <div style=\"text-align: center; margin-bottom: 15px;\">\n",
    "    <div style=\"font-size: 20px; color: #64748b;\">‚Üì</div>\n",
    "  </div>\n",
    "  <div style=\"display: flex; justify-content: center; gap: 15px; margin-bottom: 15px; flex-wrap: wrap;\">\n",
    "    <div style=\"background: #dcfce7; padding: 10px 16px; border-radius: 6px; color: #166534; font-weight: 600; min-width: 100px; text-align: center;\">Option A</div>\n",
    "    <div style=\"background: #dcfce7; padding: 10px 16px; border-radius: 6px; color: #166534; font-weight: 600; min-width: 100px; text-align: center;\">Option B</div>\n",
    "    <div style=\"background: #dcfce7; padding: 10px 16px; border-radius: 6px; color: #166534; font-weight: 600; min-width: 100px; text-align: center;\">Option C</div>\n",
    "  </div>\n",
    "  <div style=\"text-align: center; margin-bottom: 15px;\">\n",
    "    <div style=\"font-size: 20px; color: #64748b;\">‚Üì</div>\n",
    "  </div>\n",
    "  <div style=\"text-align: center; margin-bottom: 15px;\">\n",
    "    <div style=\"background: #fef3c7; padding: 12px 20px; border-radius: 6px; display: inline-block; color: #92400e; font-weight: 600;\">Evaluate all approaches</div>\n",
    "  </div>\n",
    "  <div style=\"text-align: center; margin-bottom: 15px;\">\n",
    "    <div style=\"font-size: 20px; color: #64748b;\">‚Üì</div>\n",
    "  </div>\n",
    "  <div style=\"text-align: center;\">\n",
    "    <div style=\"background: #dbeafe; padding: 12px 20px; border-radius: 6px; display: inline-block; color: #1e40af; font-weight: 600;\">Select best with reason</div>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "**Example use case:** Algorithm selection, architecture decisions, library comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "from setup_utils import get_chat_completion_async, run_async\n",
    "\n",
    "problem = \"Find duplicates in 1 million records\"\n",
    "\n",
    "async def generate_approach(approach_name, problem):\n",
    "    messages = [{\"role\": \"user\", \"content\": f\"\"\"{problem}\n",
    "\n",
    "Generate approach: {approach_name}\n",
    "Provide: Name, algorithm, time/space complexity\"\"\"}]\n",
    "    return await get_chat_completion_async(messages)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SEQUENTIAL vs PARALLEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Sequential: one at a time\n",
    "print(\"\\nSequential (one at a time):\")\n",
    "print(\"-\" * 70)\n",
    "start_seq = time.time()\n",
    "\n",
    "approach_a = get_chat_completion([{\"role\": \"user\", \"content\": f\"\"\"{problem}\n",
    "Generate approach: Hash Set\n",
    "Provide: Name, algorithm, time/space complexity\"\"\"}])\n",
    "print(f\"‚úì Hash Set ({time.time() - start_seq:.1f}s)\")\n",
    "\n",
    "approach_b = get_chat_completion([{\"role\": \"user\", \"content\": f\"\"\"{problem}\n",
    "Generate approach: Sorting\n",
    "Provide: Name, algorithm, time/space complexity\"\"\"}])\n",
    "print(f\"‚úì Sorting ({time.time() - start_seq:.1f}s)\")\n",
    "\n",
    "approach_c = get_chat_completion([{\"role\": \"user\", \"content\": f\"\"\"{problem}\n",
    "Generate approach: Nested Loops\n",
    "Provide: Name, algorithm, time/space complexity\"\"\"}])\n",
    "print(f\"‚úì Nested Loops ({time.time() - start_seq:.1f}s)\")\n",
    "\n",
    "sequential_time = time.time() - start_seq\n",
    "print(f\"\\nTotal: {sequential_time:.1f} seconds\")\n",
    "\n",
    "# Parallel: all at once\n",
    "print(\"\\nParallel (all at once):\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "async def generate_all_parallel():\n",
    "    start = time.time()\n",
    "    results = await asyncio.gather(\n",
    "        generate_approach(\"Hash Set\", problem),\n",
    "        generate_approach(\"Sorting\", problem),\n",
    "        generate_approach(\"Nested Loops\", problem)\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    return results, elapsed\n",
    "\n",
    "results, parallel_time = run_async(generate_all_parallel())\n",
    "\n",
    "approach_a_par, approach_b_par, approach_c_par = results\n",
    "\n",
    "print(f\"‚úì All 3 generated in parallel\")\n",
    "print(f\"Total: {parallel_time:.1f} seconds\")\n",
    "print(f\"Speedup: {sequential_time / parallel_time:.1f}x faster\\n\")\n",
    "\n",
    "# Step 2: Evaluate all approaches\n",
    "print(\"=\" * 70)\n",
    "print(\"Step 2: Evaluate approaches\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "alternatives = f\"\"\"Hash Set: {approach_a_par}\n",
    "\n",
    "Sorting: {approach_b_par}\n",
    "\n",
    "Nested Loops: {approach_c_par}\"\"\"\n",
    "\n",
    "evaluation = get_chat_completion([{\"role\": \"user\", \"content\": f\"\"\"Compare these approaches for finding duplicates in 1M records:\n",
    "\n",
    "{alternatives}\n",
    "\n",
    "Score each 1-10 on:\n",
    "- Performance (time complexity)\n",
    "- Memory usage\n",
    "- Scalability\n",
    "- Code simplicity\n",
    "\n",
    "Format as a comparison table.\"\"\"}])\n",
    "print(evaluation)\n",
    "\n",
    "# Step 3: Pick the winner\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Step 3: Select best approach\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "selection = get_chat_completion([{\"role\": \"user\", \"content\": f\"\"\"Based on this evaluation:\n",
    "\n",
    "{evaluation}\n",
    "\n",
    "Which approach is best for 1M records? Explain why.\"\"\"}])\n",
    "print(selection)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Takeaway\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Parallel execution saved {sequential_time - parallel_time:.1f} seconds.\")\n",
    "print(\"Generated 3 options ‚Üí Compared them ‚Üí Picked the best.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Try It Yourself: Prompt Chaining Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Common Misconception:** AI can handle complex decisions in one prompt as well as breaking them into focused steps.\n",
    "\n",
    "**The Reality:** Chaining patterns give each task full attention, dramatically improving quality.\n",
    "\n",
    "**Your Task:** Try the parallel exploration pattern. Compare single-path vs exploring multiple alternatives.\n",
    "\n",
    "**Before you start, think about:**\n",
    "\n",
    "Could you please share:\n",
    "\n",
    "- What options are you choosing between?\n",
    "\n",
    "- What type of system/solution is this for?\n",
    "\n",
    "- What are your priorities (performance vs. cost vs. simplicity)?\n",
    "\n",
    "**Example answers:**\n",
    "\n",
    "For the caching example below:\n",
    "- **Options:** Client-side (browser cache), CDN (edge caching), Server-side (Redis/Memcached)\n",
    "- **System type:** API caching strategies to reduce database load\n",
    "- **Priorities:** Latency reduction, DB load reduction, Cost, Complexity, Cache invalidation ease\n",
    "\n",
    "Use these answers to customize the example code below with your specific problem and options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå BAD: Single path (first idea that comes to mind)\n",
    "print(\"Single Path Approach:\")\n",
    "single = get_chat_completion([{\"role\": \"user\", \"content\": \"Design caching for API to reduce DB load\"}])\n",
    "print(single)\n",
    "print()\n",
    "\n",
    "# ‚úÖ YOUR TURN: Uncomment for parallel decision support approach\n",
    "# import asyncio\n",
    "# from setup_utils import get_chat_completion_async, run_async\n",
    "\n",
    "# # Customize these values based on your specific decision:\n",
    "# # - problem: What type of system/solution is this for?\n",
    "# #   Example: \"API caching strategies to reduce DB load\"\n",
    "# # - option names: What options are you choosing between?\n",
    "# #   Example: [\"Client-side (browser cache)\", \"CDN (edge caching)\", \"Server-side (Redis/Memcached)\"]\n",
    "# # - evaluation criteria: What are your priorities (performance vs. cost vs. simplicity)?\n",
    "# #   Example: Latency reduction, DB load reduction, Cost, Complexity, Cache invalidation ease\n",
    "# problem = \"API caching strategies to reduce DB load\"\n",
    "\n",
    "# async def generate_option(option_name, problem):\n",
    "#     \"\"\"Generate a single caching option asynchronously.\"\"\"\n",
    "#     messages = [{\"role\": \"user\", \"content\": f\"\"\"You are a systems architect designing caching solutions.\n",
    "\n",
    "# Context: {problem}\n",
    "\n",
    "# Generate a detailed approach for: {option_name}\n",
    "\n",
    "# Provide a comprehensive explanation covering:\n",
    "\n",
    "# 1. **How it works**: Explain the mechanism and architecture\n",
    "# 2. **What it caches**: Specify what data/content is cached\n",
    "# 3. **TTL (Time To Live)**: Recommended cache expiration strategy\n",
    "# 4. **Implementation details**: \n",
    "#    - Required infrastructure/components\n",
    "#    - Code examples or configuration snippets\n",
    "#    - Integration points\n",
    "#    - Key considerations or limitations\n",
    "\n",
    "# Format your response clearly with section headers for each part.\"\"\"}]\n",
    "#     return await get_chat_completion_async(messages)\n",
    "\n",
    "# print(\"=\" * 70)\n",
    "# print(\"Decision Support Approach: Parallel Exploration\")\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "# # Step 1: Generate all options in parallel\n",
    "# # This step uses async/await to generate multiple options simultaneously.\n",
    "# # Instead of waiting for each option one-by-one, asyncio.gather() runs all three\n",
    "# # API calls concurrently, dramatically reducing total wait time.\n",
    "# print(\"\\nStep 1: Generate all options in parallel\")\n",
    "# print(\"-\" * 70)\n",
    "\n",
    "# async def generate_all_options():\n",
    "#     # asyncio.gather() runs all three async calls concurrently\n",
    "#     # Returns results in the same order as the input arguments\n",
    "#     results = await asyncio.gather(\n",
    "#         generate_option(\"Client-side (browser cache)\", problem),\n",
    "#         generate_option(\"CDN (edge caching)\", problem),\n",
    "#         generate_option(\"Server-side (Redis/Memcached)\", problem)\n",
    "#     )\n",
    "#     return results\n",
    "\n",
    "# results = run_async(generate_all_options())\n",
    "# client_side, cdn, server_side = results\n",
    "\n",
    "# print(\"‚úì Client-side option generated\")\n",
    "# print(\"‚úì CDN option generated\")\n",
    "# print(\"‚úì Server-side option generated\\n\")\n",
    "\n",
    "# # Step 2: Evaluate all approaches\n",
    "# # Now that we have all options, we compare them using structured criteria.\n",
    "# # This step is sequential (not parallel) because it depends on Step 1's output.\n",
    "# # The AI evaluates each option against the same criteria for fair comparison.\n",
    "# print(\"=\" * 70)\n",
    "# print(\"Step 2: Evaluate all approaches\")\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "# alternatives = f\"\"\"Client-side: {client_side}\n",
    "\n",
    "# CDN: {cdn}\n",
    "\n",
    "# Server-side: {server_side}\"\"\"\n",
    "\n",
    "# scores = get_chat_completion([\n",
    "#     {\"role\": \"system\", \"content\": \"You are an expert systems architect. You MUST format your evaluations as markdown tables with numeric scores.\"},\n",
    "#     {\"role\": \"user\", \"content\": f\"\"\"Evaluate these caching options and provide scores in a comparison table.\n",
    "\n",
    "# <context>\n",
    "# {problem}\n",
    "# </context>\n",
    "\n",
    "# <options_to_evaluate>\n",
    "# {alternatives}\n",
    "# </options_to_evaluate>\n",
    "\n",
    "# <evaluation_criteria>\n",
    "# Score each option from 1-10 (where 10 is best) on:\n",
    "# 1. Latency Reduction - How much does this reduce response time?\n",
    "# 2. DB Load Reduction - How much does this reduce database queries?\n",
    "# 3. Cost - Lower cost = higher score (infrastructure, maintenance, etc.)\n",
    "# 4. Complexity - Lower complexity = higher score (implementation and maintenance)\n",
    "# 5. Cache Invalidation Ease - How easy is it to invalidate/update cached data?\n",
    "\n",
    "# Overall Score = sum of all 5 criteria (max 50)\n",
    "# </evaluation_criteria>\n",
    "\n",
    "# <output_format>\n",
    "# You MUST respond with a markdown table. Here is the EXACT format required:\n",
    "\n",
    "# ## Comparison Table\n",
    "\n",
    "# | Option | Latency Reduction | DB Load Reduction | Cost | Complexity | Cache Invalidation Ease | Overall Score |\n",
    "# |--------|-------------------|-------------------|------|------------|------------------------|---------------|\n",
    "# | Client-side | 8/10 | 3/10 | 9/10 | 7/10 | 4/10 | 31/50 |\n",
    "# | CDN | 9/10 | 7/10 | 5/10 | 6/10 | 5/10 | 32/50 |\n",
    "# | Server-side | 6/10 | 9/10 | 7/10 | 6/10 | 8/10 | 36/50 |\n",
    "\n",
    "# ## Key Trade-offs\n",
    "\n",
    "# [Your analysis here]\n",
    "# </output_format>\n",
    "\n",
    "# Now evaluate the three options above and provide your scores in the table format shown. Replace the example scores with your actual evaluation.\"\"\"}\n",
    "# ])\n",
    "# print(scores)\n",
    "\n",
    "# # Step 3: Recommend best option\n",
    "# # Final step uses the evaluation scores to make a decision.\n",
    "# # This is sequential because it needs the scores from Step 2.\n",
    "# # The AI synthesizes the evaluation data to recommend the best option or hybrid approach.\n",
    "# # IMPORTANT: Include all context (problem, options, criteria, scores) so AI has full picture.\n",
    "# print(\"\\n\" + \"=\" * 70)\n",
    "# print(\"Step 3: Select best approach\")\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "# best = get_chat_completion([{\"role\": \"user\", \"content\": f\"\"\"Context: {problem}\n",
    "\n",
    "# Options evaluated:\n",
    "# {alternatives}\n",
    "\n",
    "# Evaluation results:\n",
    "# {scores}\n",
    "\n",
    "# Based on the evaluation above, recommend the best option (or hybrid approach) for this use case.\n",
    "# Justify your choice by referencing specific scores and trade-offs from the evaluation.\"\"\"}])\n",
    "# print(best)\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 70)\n",
    "# print(\"Takeaway\")\n",
    "# print(\"=\" * 70)\n",
    "# print(\"Generated 3 options in parallel ‚Üí Compared them ‚Üí Picked the best.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "**Prompt chaining: One technique, three patterns**\n",
    "\n",
    "| Pattern | Use Case | Steps | Cost |\n",
    "|---------|----------|-------|------|\n",
    "| **Sequential Workflow** | Linear multi-step tasks | Step 1 ‚Üí Step 2 ‚Üí Step 3 (different focuses) | $$ |\n",
    "| **Self-Correction** | Quality improvement | Generate ‚Üí Critique ‚Üí Improve (role switch) | $$ |\n",
    "| **Parallel Exploration** | Choosing between options | Generate N ‚Üí Evaluate ‚Üí Select best | $$$ |\n",
    "\n",
    "**Best Practices:**\n",
    "1. **One focus per step:** Each prompt has a single, clear objective\n",
    "2. **Sequential dependencies:** Later steps use earlier outputs as input\n",
    "3. **XML structure:** Tags like `<analysis>`, `<code>`, `<options>` pass data cleanly\n",
    "4. **Role switching:** AI can act as creator then critic (self-correction)\n",
    "5. **Weighted criteria:** Prioritize what matters (security > style)\n",
    "\n",
    "**When to use chaining:**\n",
    "- Multi-step workflows (analyze ‚Üí fix ‚Üí test)\n",
    "- Quality-critical tasks (code reviews, security audits)\n",
    "- Complex decisions with multiple viable approaches\n",
    "- Need to verify each intermediate stage\n",
    "\n",
    "**When NOT to use:**\n",
    "- Simple, single-step tasks\n",
    "- Speed matters more than quality\n",
    "- No intermediate verification needed\n",
    "- Clear best practices already exist\n",
    "\n",
    "**Cost reality:**\n",
    "- Single prompt: 1 call\n",
    "- Sequential/Self-correction: 2-3 calls\n",
    "- Parallel exploration: 3-7 calls (N alternatives + evaluation + selection)\n",
    "\n",
    "More calls = better quality. Use strategically for important decisions and complex tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div style=\"margin:24px 0; padding:20px 24px; background:linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%); border-radius:12px; border-left:5px solid #10b981; box-shadow:0 2px 8px rgba(0,0,0,0.1);\">\n",
    "  <div style=\"color:#1e293b; font-size:0.85em; font-weight:600; text-transform:uppercase; letter-spacing:1px; margin-bottom:8px;\">‚è≠Ô∏è Next Section</div>\n",
    "  <div style=\"color:#0f172a; font-size:1.15em; font-weight:700; margin-bottom:6px;\">Section 2.5: Hands-On Practice</div>\n",
    "  <div style=\"color:#475569; font-size:0.95em; line-height:1.5; margin-bottom:12px;\">Apply all tactics independently in unguided practice activities with automated evaluation.</div>\n",
    "  <a href=\"./2.5-hands-on-practice.ipynb\" style=\"display:inline-block; padding:8px 16px; background:#10b981; color:#fff; text-decoration:none; border-radius:6px; font-weight:600; font-size:0.9em; transition:all 0.2s;\">Continue to Section 2.5 ‚Üí</a>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
