# Section 2.2: Roles and Structure - Prompt Templates

> **üìã For Circuit Users (No API Access Required)**
>
> This guide extracts the key prompts from `2.2-roles-and-structure.ipynb` into copy-paste templates for use in web-based AI chat interfaces like Cisco's internal Circuit.

| **Aspect** | **Details** |
|-------------|-------------|
| **Goal** | Master role prompting personas and structured input patterns |
| **Time** | ~20 minutes |
| **Prerequisites** | Access to a AI chat web interface (internal Cisco Curcuit, ChatGPT Plus, etc.) |
| **Next Steps** | Continue to Section 2.3: Patterns for Reasoning |

---

## üéØ Learning Objectives

By the end of this section, you'll be able to:
- ‚úÖ Use role prompting to transform AI into specialized domain experts
- ‚úÖ Organize complex inputs with XML delimiters
- ‚úÖ Apply these tactics to code review scenarios

---

## üé≠ Tactic 1: Role Prompting

**Transform AI into specialized domain experts**

Role prompting uses the system parameter (or context) to give the AI a specific persona with domain expertise. This enhances accuracy, tailors communication tone, and keeps responses focused on your task.

### üìù Example 1: Code Reviewer Persona

**Copy this to Circuit:**

```
You are a code reviewer. Analyze the provided code and give exactly 3 specific feedback points: 1 about code structure, 1 about naming conventions, and 1 about potential improvements. Format each point as a bullet with the category in brackets.

Code to review:
def calc(x, y): return x + y if x > 0 and y > 0 else 0
```

**‚úÖ Self-Check: Your response should include:**
- [ ] Exactly 3 feedback points (not more, not less)
- [ ] Clear categories in brackets: [Structure], [Naming], [Improvements]
- [ ] Specific, actionable advice
- [ ] Professional code review tone

---

### üìù Example 2: Security Engineer Persona

**Copy this to Circuit:**

```
You are a security engineer. Review code for security vulnerabilities and provide specific recommendations.

Review this login function:

def login(username, password):
    query = f"SELECT * FROM users WHERE username = '{username}' AND password = '{password}'"
    result = database.execute(query)
    return result
```

**‚úÖ Self-Check: Your response should include:**
- [ ] Identified SQL injection vulnerability
- [ ] Mentioned password storage issues (plaintext)
- [ ] Provided specific remediation steps
- [ ] Security-focused language and severity levels

**üí° Key Insight:** Notice how the security engineer immediately spots SQL injection! A generic "code reviewer" might miss it or give it less emphasis.

---

## üéØ Activity 1.1: Try It Yourself - Role Prompting

**Scenario:** You have a function with potential issues. Compare generic vs. specialized review.

### Step 1: Generic Review (No Role)

**Copy this to Circuit:**

```
Review this code:

def get_user_data(user_id):
    query = f"SELECT * FROM users WHERE id = {user_id}"
    results = db.execute(query).fetchall()
    return results
```

**Note what the AI finds...**

---

### Step 2: Specialized Review (With Role)

**Now copy this to Circuit (same chat or new chat):**

```
You are a Security Engineer. Review code specifically for security vulnerabilities including SQL injection, authentication issues, and data exposure risks. Provide severity ratings.

Review this code:

def get_user_data(user_id):
    query = f"SELECT * FROM users WHERE id = {user_id}"
    results = db.execute(query).fetchall()
    return results
```

### üìä Self-Evaluation Checklist

Compare both responses. The Security Engineer version should:
- [ ] Immediately highlight SQL injection as CRITICAL or HIGH severity
- [ ] Mention parameterized queries as the solution
- [ ] Discuss data exposure risks (SELECT *)
- [ ] Include specific code examples for fixes
- [ ] Use security-specific terminology

**Score yourself:**
- **5/5 checks** = Excellent! The role made a significant difference ‚úÖ
- **3-4/5 checks** = Good, the role improved focus
- **0-2/5 checks** = Try being more specific in the role description

---

## üìã Tactic 2: Structured Inputs

**Organize complex scenarios with delimiters**

When prompts involve multiple components (context, instructions, examples), delimiters help AI parse inputs accurately, leading to higher-quality outputs.

### Understanding Delimiters

**Simple Delimiters (`###`):**
- Visual section headers within prompts
- Example: `### CODE ###` followed by code, then `### REQUIREMENTS ###`

**XML Delimiters (More Powerful):**
- LLMs are trained extensively on XML/HTML structure
- Create descriptive tags: `<user_input>`, `<test_cases>`, `<requirements>`
- Best for complex, multi-part inputs

**Why This Works:**
- **Clarity** - Clearly separate different parts of your prompt
- **Accuracy** - Reduce misinterpretation errors
- **Flexibility** - Easily modify sections without rewriting everything
- **Parseability** - Easier to extract specific parts from AI responses

---

### üìù Example 3: Simple Delimiters

**Copy this to Circuit:**

```
You are a Python code reviewer. Provide only the refactored code without explanations.

Refactor this function based on the requirements:

### CODE ###
def process_data(items): return [x.upper() for x in items if len(x) > 3]
###

### REQUIREMENTS ###
Follow PEP 8 style guide, add type hints, improve readability
###

Return only the improved function code.
```

**‚úÖ Self-Check: Your response should:**
- [ ] Include type hints (List, str, etc.)
- [ ] Use proper line breaks and formatting (not one-liner)
- [ ] Follow PEP 8 naming conventions
- [ ] Include only code (no explanations)

---

### üìù Example 4: XML Delimiters for Multi-File Analysis

**Copy this to Circuit:**

```
You are a software architect. Analyze the provided files and identify architectural concerns.

<user_model>
class User:
    def __init__(self, email, password):
        self.email = email
        self.password = password

    def save(self):
        # Save to database
        pass
</user_model>

<user_controller>
from flask import Flask, request
app = Flask(__name__)

@app.route('/register', methods=['POST'])
def register():
    email = request.form['email']
    password = request.form['password']
    user = User(email, password)
    user.save()
    return "User registered"
</user_controller>

<requirements>
- Follow separation of concerns
- Add input validation
- Implement proper error handling
- Use dependency injection
</requirements>

Provide architectural recommendations for improving this code structure.
```

**‚úÖ Self-Check: Your response should:**
- [ ] Reference specific tags (<user_model>, <user_controller>, etc.)
- [ ] Address separation of concerns (data/business/presentation layers)
- [ ] Mention input validation issues
- [ ] Suggest architectural patterns (repository pattern, service layer)
- [ ] Provide concrete refactoring steps

---

## üéØ Activity 1.2: Try It Yourself - Structured Inputs

**Scenario:** You have a messy prompt with requirements, code, and context all jumbled together. See how structure improves the response.

### Step 1: Messy Prompt (No Structure)

**Copy this to Circuit:**

```
I need to refactor this function: def send_email(to, subject, body): smtp.send(to, subject, body)

The requirements are: add error handling, implement retry logic with exponential backoff, add logging, and validate email format. This is for a high-traffic notification service that sends 10k emails per hour. The current implementation fails silently when SMTP server is down and doesn't validate email addresses. We need 99.9% delivery rate.

Please refactor this code following best practices.
```

**Note the response quality...**

---

### Step 2: Structured Prompt (With XML Tags)

**Now copy this to Circuit (new chat recommended):**

```
<current_code>
def send_email(to, subject, body):
    smtp.send(to, subject, body)
</current_code>

<context>
This is for a high-traffic notification service that sends 10k emails per hour.
Current implementation fails silently when SMTP server is down.
Email addresses are not validated.
We need 99.9% delivery rate.
</context>

<requirements>
1. Add error handling
2. Implement retry logic with exponential backoff
3. Add logging for monitoring
4. Validate email format before sending
5. Follow Python best practices
</requirements>

Please refactor this code addressing all requirements.
```

### üìä Self-Evaluation Checklist

Compare both responses. The structured version should be:
- [ ] More organized (addresses each requirement separately)
- [ ] More complete (doesn't miss requirements)
- [ ] Includes all requested features (error handling, retry, logging, validation)
- [ ] Provides better code structure (classes, proper exception handling)
- [ ] Easier to read and implement

**Score yourself:**
- **5/5 checks** = Excellent! Structure made a huge difference ‚úÖ
- **3-4/5 checks** = Good improvement with structure
- **0-2/5 checks** = Try using more specific tag names like `<system_requirements>` instead of generic ones

---

## üéñÔ∏è Skill Tracker

After completing the activities above, check off the skills you've mastered:

### Role Prompting Skills
- [ ] **Skill #1:** I can create effective software engineering personas (Security Engineer, QA Engineer, etc.)
- [ ] **Skill #2:** I can assign specific expertise roles to get specialized analysis
- [ ] **Skill #3:** I can compare generic vs. specialized reviews to see the impact

### Structured Inputs Skills
- [ ] **Skill #4:** I can use simple delimiters (`###`) to organize prompt sections
- [ ] **Skill #5:** I can use XML tags (`<code>`, `<requirements>`) for complex inputs
- [ ] **Skill #6:** I can handle multi-file scenarios with clear structure
- [ ] **Skill #7:** I can distinguish between different types of information using tags

**üèÜ Mastery Level:**
- **7/7 skills** = Expert! Ready for advanced tactics ‚úÖ
- **5-6/7 skills** = Proficient! Practice the missing skills
- **3-4/7 skills** = Good start! Revisit examples above
- **0-2/7 skills** = Keep practicing! Try each example again

---

## üí° Key Takeaways

### When to Use Role Prompting
‚úÖ Code reviews with specific focus (security, performance, accessibility)
‚úÖ Domain-specific analysis (fintech, healthcare, e-commerce)
‚úÖ Different expertise levels (junior vs. senior engineer perspective)
‚úÖ Specialized documentation (API docs, user guides, technical specs)

### When to Use Structured Inputs
‚úÖ Multi-file refactoring or analysis
‚úÖ Separating code from requirements
‚úÖ Complex scenarios with multiple context pieces
‚úÖ When you need AI to reference specific sections
‚úÖ Pull request reviews with description + code + tests

### Best Practices Learned
1. **Be specific with roles** - "Security Engineer specializing in OWASP Top 10" > "security expert"
2. **Use descriptive XML tags** - `<source_code>` > `<input>`
3. **Combine tactics** - Role prompting + structured inputs = powerful combination
4. **Keep sections focused** - Each tag should contain one type of information

---

## ‚è≠Ô∏è Next Steps

<div style="background:rgb(12, 88, 160); padding: 16px; border-radius: 8px; border-left: 4px solid #3b82f6;">

**Continue to Section 2.3: Patterns for Reasoning**

Learn how to use:
- üìö **Few-shot examples** to teach AI your coding style
- ‚õìÔ∏è **Chain-of-thought** for systematic debugging and analysis
- üìñ **Reference citations** to ground responses in documentation

[View 2.3-prompt-templates.md](./2.3-prompt-templates.md) ‚Üí

</div>

---

## ü§î Troubleshooting

**Q: The AI's response doesn't match the checklist items**
**A:** Try these fixes:
1. Be more explicit in your role description
2. Add "Format your response as: [specific structure]"
3. Try a different chat session (clear context)

**Q: The structured prompt still seems messy**
**A:** Make sure:
1. Each XML tag is on its own line
2. Opening and closing tags match exactly
3. Tags describe their content clearly

**Q: Can I use this with Cisco's internal Circuit?**
**A:** Yes! These prompts work with any AI chat interface. Just copy-paste the text between the code blocks.

---

## üìö Related Resources

- [Claude Documentation - System Prompts](https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/system-prompts)
- [Claude Documentation - XML Tags](https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags)
- [Full Interactive Notebook](./2.2-roles-and-structure.ipynb) (requires API access)

---

**üìù Note:** This template guide is a companion to the full Jupyter notebook. If you have API access (GitHub Copilot, OpenAI, Claude), use the interactive notebook for automated evaluation and progress tracking.