# Section 2.5: Hands-On Practice - Prompt Templates

> **üìã For Circuit Users (No API Access Required)**
>
> This guide provides hands-on practice activities to apply all 8 tactics independently. Test your skills with real-world scenarios!

| **Aspect** | **Details** |
|-------------|-------------|
| **Goal** | Apply all 8 tactics independently in unguided practice activities |
| **Time** | ~20 minutes |
| **Prerequisites** | Complete Sections 2.1‚Äì2.4 and understand all 8 core tactics |
| **Next Steps** | Advance to Module 3: Applications |

---

## üéØ Learning Objectives

By the end of this section, you'll be able to:
- ‚úÖ Apply all 8 tactics independently without guided hints
- ‚úÖ Combine multiple tactics in complex scenarios
- ‚úÖ Self-evaluate your prompts against success criteria
- ‚úÖ Recognize which tactics to use for different tasks

---

## üéñÔ∏è How to Use This Section

### Self-Evaluation Process
1. **Read the scenario** - Understand the task and requirements
2. **Write your prompt** - Apply the relevant tactics independently
3. **Check success criteria** - Compare your prompt against the checklist
4. **Score yourself** - Count how many criteria you met
5. **Iterate** - If you scored low, revise and try again

### Mastery Thresholds
- **‚úÖ Excellent:** 4-5 criteria met (ready to move on!)
- **‚ö†Ô∏è Good:** 3 criteria met (review examples, try once more)
- **‚ùå Needs Work:** 0-2 criteria met (revisit the tactic's section)

---

## üéØ Activity 1: Role Prompting & Structured Inputs

### Scenario
You have test and source code files for a shopping cart system. You need a QA Engineer to analyze test coverage gaps.

**Test File:**
```python
def calculate_total(items, tax_rate=0.1):
    subtotal = sum(item['price'] * item['quantity'] for item in items)
    return subtotal * (1 + tax_rate)
```

**Source Code:**
```python
class ShoppingCart:
    def __init__(self):
        self.items = []

    def add_item(self, name, price, quantity=1):
        self.items.append({'name': name, 'price': price, 'quantity': quantity})

    def get_total(self, tax_rate=0.1):
        return calculate_total(self.items, tax_rate)
```

### Your Task
Write a prompt that:
1. Assigns the AI a QA Engineer role
2. Uses XML tags to separate test_file and source_code
3. Requests test coverage analysis

**Copy this template to Circuit and fill in the blanks:**

```
[YOUR SYSTEM ROLE HERE - e.g., "You are a QA Engineer specializing in..."]

Analyze test coverage for this codebase:

<test_file>
[PASTE TEST FILE HERE]
</test_file>

<source_code>
[PASTE SOURCE CODE HERE]
</source_code>

[YOUR REQUEST HERE - e.g., "Identify test coverage gaps and..."]
```

### ‚úÖ Success Criteria
Check off what your prompt includes:
- [ ] System message with QA Engineer role (or similar testing expert)
- [ ] XML tags wrapping the test file content
- [ ] XML tags wrapping the source code
- [ ] Clear request for test coverage analysis
- [ ] Asks for specific output (gaps, missing tests, recommendations)

**Score: ___/5**

---

## üéØ Activity 2: Few-Shot Examples & Chain-of-Thought

### Scenario
You need to add error messages to a new function using your team's established style. The AI should learn your style from examples, then apply chain-of-thought reasoning to generate consistent messages.

**Your Team's Error Message Style:**
- Start with action verb (e.g., "Failed to...")
- Include specific cause
- Suggest remedy
- Professional tone

**New Function Needing Error Messages:**
```python
def transfer_funds(from_account, to_account, amount, currency='USD'):
    if amount <= 0:
        raise ValueError("Amount must be positive")
    if from_account == to_account:
        raise ValueError("Cannot transfer to same account")
    # Transfer logic here...
```

### Your Task
Write a prompt that:
1. Provides 2-3 few-shot examples showing your error message style
2. Requests step-by-step reasoning (chain-of-thought)
3. Asks AI to apply the style to the new function

**Copy this template to Circuit and fill in the blanks:**

```
Learn from these error message examples:

EXAMPLE 1:
Code: if balance < amount: raise ValueError("...")
Error Message: "Failed to process withdrawal: insufficient balance. Remedy: Reduce amount or deposit funds."

EXAMPLE 2:
Code: if not account_exists(id): raise ValueError("...")
Error Message: "Failed to locate account: ID not found in system. Remedy: Verify account number and retry."

[ADD YOUR EXAMPLE 3 HERE]

Now apply this style to improve error messages in this function:

```python
def transfer_funds(from_account, to_account, amount, currency='USD'):
    if amount <= 0:
        raise ValueError("Amount must be positive")
    if from_account == to_account:
        raise ValueError("Cannot transfer to same account")
```

Think step-by-step:
1. Analyze each error condition
2. Apply the pattern from examples
3. Generate improved error messages

Provide improved error messages matching the example style.
```

### ‚úÖ Success Criteria
Check off what your prompt includes:
- [ ] 2-3 few-shot examples showing clear error message pattern
- [ ] Examples demonstrate: action verb, cause, remedy, professional tone
- [ ] Request for step-by-step reasoning (explicit mention)
- [ ] Function code to improve
- [ ] Clear instruction to apply learned style

**Score: ___/5**

---

## üéØ Activity 3: Reference Citations & Prompt Chaining

### Scenario
Build a 2-step chain: (1) Extract quotes from API documentation, (2) Generate code using those quotes.

**API Documentation:**
```
# Authentication API v2

## Security Requirements
All API requests must include:
- API key in X-API-Key header
- Request signature using HMAC-SHA256
- Timestamp within 5 minutes of server time
- Rate limiting: 100 requests per minute per key

## Key Management
- Store keys in environment variables, never in code
- Rotate keys every 90 days
- Use separate keys for dev/staging/production

## Error Handling
- 401: Invalid or missing API key
- 403: Valid key but insufficient permissions
- 429: Rate limit exceeded
```

### Your Task
Create a 2-step prompt chain:

**Step 1: Extract Quotes**

**Copy this to Circuit:**

```
<documents>
<document index="1">
<source>authentication_api_v2.md</source>
<document_content>
[PASTE API DOCUMENTATION HERE]
</document_content>
</document>
</documents>

Task: I need to implement API authentication for a Python client.

Step 1: Extract relevant quotes from the documentation that cover:
- Required headers and authentication method
- Key storage best practices
- Error codes to handle

Wrap extracted quotes in <quotes> tags with section names indicated.
```

**Save the quotes response!**

---

**Step 2: Generate Code Using Quotes**

**Copy this to Circuit (same chat or new):**

```
Using ONLY the quotes extracted in Step 1:

<quotes>
[PASTE THE QUOTES FROM STEP 1 HERE]
</quotes>

Now generate Python code for an API client that:
- Implements authentication using the quoted requirements
- Stores keys according to best practices mentioned
- Handles all error codes from the quotes

Provide implementation in <code> tags.
```

### ‚úÖ Success Criteria
Check off what your prompts include:
- [ ] Step 1 uses XML tags (<documents>, <document>, <source>, <document_content>)
- [ ] Step 1 explicitly requests quote extraction in <quotes> tags
- [ ] Step 2 references the quotes from Step 1
- [ ] Step 2 instructs to use "ONLY the quoted information"
- [ ] The chain passes context from Step 1 to Step 2

**Score: ___/5**

---

## üéØ Activity 4: Tree of Thoughts & LLM-as-Judge

### Scenario
Choose the best approach for email validation by exploring 3 alternatives, evaluating them, and selecting the winner.

### Your Task
Create a tree-of-thoughts exploration with LLM-as-judge evaluation:

**Step 1: Generate 3 Alternatives**

**Copy this to Circuit:**

```
Generate 3 DIFFERENT approaches to validate email addresses:

Approach A: Regex-based validation
Approach B: Library-based validation (using email-validator pattern)
Approach C: Custom parser validation (manually parsing email parts)

For each approach, provide:
- Implementation strategy
- Pros and cons
- Time/space complexity estimate

Use this format:
<approach_a>
Strategy: [how it works]
Pros: [advantages]
Cons: [disadvantages]
Complexity: [estimate]
</approach_a>

[Repeat for approaches B and C]
```

---

**Step 2: Judge with Weighted Rubric**

**Copy this to Circuit (same chat):**

```
You are a senior software architect. Evaluate the 3 approaches you proposed using weighted criteria:

**Security (40% weight):**
- Injection vulnerability resistance
- Edge case handling
- Score 0-10

**Performance (30% weight):**
- Speed/efficiency
- Resource usage
- Score 0-10

**Maintainability (30% weight):**
- Code clarity
- Ease of modification
- Score 0-10

For each approach:
1. Score on all criteria
2. Calculate weighted total
3. Identify strengths and weaknesses

Provide comparison in table format.
```

---

**Step 3: Select Winner**

**Copy this to Circuit (same chat):**

```
Based on your evaluation, select the BEST approach for email validation.

Provide:
- Winner: Approach [A/B/C]
- Justification: Why it wins on the most important criteria
- Trade-offs: What you're giving up
- When to use it: Best use cases for this approach
```

### ‚úÖ Success Criteria
Check off what your prompts include:
- [ ] Step 1 generates exactly 3 distinct approaches
- [ ] Step 2 uses weighted evaluation (Security 40%, Performance 30%, Maintainability 30%)
- [ ] Step 2 requests scores (0-10) for each criterion
- [ ] Step 3 asks for clear winner with justification
- [ ] The pattern explores alternatives (ToT) then judges them (LLM-as-Judge)

**Score: ___/5**

---

## üéñÔ∏è Skill Tracker - Complete Module 2 Checklist

After completing all 4 activities, assess your mastery:

### Activity 1 Skills (Role Prompting & Structured Inputs)
- [ ] **Skill #1:** I can assign specific role personas to AI
- [ ] **Skill #2:** I can use XML tags to organize complex inputs
- [ ] **Skill #3:** I can structure multi-file scenarios clearly

### Activity 2 Skills (Few-Shot & Chain-of-Thought)
- [ ] **Skill #4:** I can create 2-3 few-shot examples to teach patterns
- [ ] **Skill #5:** I can trigger step-by-step reasoning
- [ ] **Skill #6:** I can combine few-shot with CoT for consistent, systematic outputs

### Activity 3 Skills (Reference Citations & Chaining)
- [ ] **Skill #7:** I can structure documentation with proper XML tags
- [ ] **Skill #8:** I can request quote extraction before analysis
- [ ] **Skill #9:** I can chain prompts by passing context between steps

### Activity 4 Skills (Tree of Thoughts & LLM-as-Judge)
- [ ] **Skill #10:** I can generate multiple alternative approaches
- [ ] **Skill #11:** I can create weighted evaluation rubrics
- [ ] **Skill #12:** I can select optimal solutions with clear justification

**üèÜ Mastery Score:**
- **12/12 skills** = Expert! Module 2 complete ‚úÖ
- **9-11/12 skills** = Proficient! Review 1-2 tactics
- **6-8/12 skills** = Good progress! Revisit 3-4 tactics
- **0-5/12 skills** = Keep practicing! Review all sections

---

## üí° Key Combinations to Remember

### Power Combos (Use Together)
1. **Role + Structure** (Activity 1)
   - Assign expert persona + Organize with XML tags
   - Use for: Code review, multi-file analysis

2. **Few-Shot + CoT** (Activity 2)
   - Teach style with examples + Systematic reasoning
   - Use for: Consistent formatting with quality analysis

3. **Citations + Chaining** (Activity 3)
   - Ground in docs + Sequential steps
   - Use for: API integration, implementation from specs

4. **ToT + Judge** (Activity 4)
   - Explore alternatives + Evaluate with rubrics
   - Use for: Architecture decisions, technology choices

---

## üéì Module 2 Complete!

**Congratulations!** You've mastered the 8 core prompt engineering tactics:

| Tactic | When to Use | Key Benefit |
|--------|-------------|-------------|
| üé¨ **Clear Instructions** | Always! Foundation for all tactics | Eliminates ambiguity |
| üé≠ **Role Prompting** | Need specialized expertise | Domain knowledge |
| üìã **Structured Inputs** | Complex, multi-part scenarios | Organization clarity |
| üìö **Few-Shot Examples** | Teach specific styles/formats | Consistency |
| ‚õìÔ∏è **Chain-of-Thought** | Complex analysis, debugging | Systematic reasoning |
| üìñ **Reference Citations** | Ground in documentation | Reduces hallucination |
| üîó **Prompt Chaining** | Multi-step workflows | Quality through focus |
| üå≥ **Tree of Thoughts** | Explore alternatives | Better decisions |
| ‚öñÔ∏è **LLM-as-Judge** | Automated evaluation | Self-improvement |

---

## ‚è≠Ô∏è Next Steps

<div style="background:rgb(12, 88, 160); padding: 16px; border-radius: 8px; border-left: 4px solid #3b82f6;">

**Continue to Module 3: Applications**

Apply these tactics to real development workflows:
- üîç **Code review automation** - Systematic quality gates
- üß™ **Test generation** - Comprehensive test suite creation
- üìù **Documentation generation** - API docs, README files
- üîß **Debugging workflows** - Root cause analysis
- üèóÔ∏è **Architecture decisions** - Technology selection, design patterns

[View Module 3 README](../module-03-applications/README.md) ‚Üí

</div>

---

## ü§î Self-Reflection Questions

Before moving to Module 3, reflect on your learning:

1. **Which tactic felt most natural to you?**
   - This is your strength‚Äîleverage it!

2. **Which tactic was most challenging?**
   - This is your growth opportunity‚Äîpractice it in Module 3!

3. **When would you use chaining vs. tree-of-thoughts?**
   - Chaining: Known process, quality focus (90% of tasks)
   - ToT: Explore alternatives, critical decisions (10% of tasks)

4. **How will you apply these tactics in your daily work?**
   - Code reviews? Debugging? Documentation? Architecture?

---

## üìö Related Resources

- [Claude Documentation - Prompt Engineering Guide](https://docs.claude.com/en/docs/build-with-claude/prompt-engineering)
- [OpenAI Prompt Engineering Best Practices](https://platform.openai.com/docs/guides/prompt-engineering)
- [Full Interactive Notebook](./2.5-hands-on-practice.ipynb) (requires API access)
- [Module 3: Applications](../module-03-applications/README.md) - Next step!

---

**üìù Note:** This template guide is a companion to the full Jupyter notebook. If you have API access (GitHub Copilot, OpenAI, Claude), use the interactive notebook for automated evaluation and progress tracking.

**üéâ Great work completing Module 2! You're now ready to apply these tactics to real software engineering workflows in Module 3.**
