{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2.1: Setup and Foundations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Aspect** | **Details** |\n",
    "|-------------|-------------|\n",
    "| **Goal** | Master environment setup, breakpoint workflows, and Tactic 0 (clear instructions). |\n",
    "| **Time** | ~15 minutes |\n",
    "| **Prerequisites** | Module 1 completion, Python 3.8+, IDE with notebook support, API access (GitHub Copilot, CircuIT, or OpenAI) |\n",
    "| **Next Steps** | [Section 2.2: Roles and Structure](./2.2-roles-and-structure.ipynb) |\n",
    "\n",
    "---\n",
    "\n",
    "## Ready to Start?\n",
    "\n",
    "**Important:** This notebook assumes you've finished Module 1 and have API keys ready. Run the cells below to confirm everything is configured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Module 2 Overview**\n",
    "\n",
    "Module 2 is structured as five linked sections (~90-120 minutes total). Each section builds on the last, so complete them in order.\n",
    "\n",
    "**Core Sections:**\n",
    "1. [Section 2.1 - Setup and Foundations](./2.1-setup-and-foundations.ipynb) (this notebook) - 15 minutes  \n",
    "   Configure dependencies, provider access, and master Tactic 0 (clear instructions).\n",
    "2. [Section 2.2 - Roles and Structure](./2.2-roles-and-structure.ipynb) - 20 minutes  \n",
    "   Turn the AI into domain experts and organize complex inputs with XML delimiters.\n",
    "3. [Section 2.3 - Patterns for Reasoning](./2.3-patterns-for-reasoning.ipynb) - 25 minutes  \n",
    "   Layer few-shot exemplars, chain-of-thought scaffolds, and reference citations.\n",
    "4. [Section 2.4 - Advanced Workflows](./2.4-advanced-workflows.ipynb) - 20 minutes  \n",
    "   Build prompt chains for complex workflows.\n",
    "\n",
    "**Hands-On Practice:**\n",
    "5. [Section 2.5 ‚Äì Hands-On Practice](./2.5-hands-on-practice.ipynb) ‚Äî 20 minutes  \n",
    "   Apply all six tactics independently in unguided practice activities.\n",
    "\n",
    "**Recommended Path:** Complete Sections 2.1‚Äì2.4 first, then use Section 2.5 for hands-on practice and reflection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Environment Configuration\n",
    "\n",
    "### Step 1: Install Required Dependencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the required packages. Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    subprocess.run(\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\"],\n",
    "        check=True\n",
    "    )\n",
    "    print(\"\\nSUCCESS: All dependencies installed.\")\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"\\nInstallation failed.\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"   1. Ensure pip is installed: python -m ensurepip --upgrade\")\n",
    "    print(\"   2. Try manual install: pip install openai anthropic python-dotenv requests\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError: {e}\")\n",
    "    print(\"Try manual install: pip install openai anthropic python-dotenv requests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Connect to AI Model\n",
    "\n",
    "Provider configuration is in `setup_utils.py` so every notebook can reuse the same helpers. Run the cell below to load the shared utilities.\n",
    "\n",
    "**Note:** By default we use the GitHub Copilot proxy running on `http://localhost:7711`. The default provider is `claude` with model `claude-sonnet-4`.\n",
    "\n",
    "**üí° Tip:** You can change the default provider and model by adding `MODULE2_PROVIDER` and `MODULE2_OPENAI_MODEL` (or `MODULE2_CLAUDE_MODEL`) to your `.env` file. See the \"Optional: Switch providers\" section below for details.\n",
    "\n",
    "If you need direct OpenAI or CircuIT access, configure it with the helper functions after this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick setup check - imports setup_utils\n",
    "try:\n",
    "    import importlib\n",
    "    import setup_utils\n",
    "    importlib.reload(setup_utils)\n",
    "    from setup_utils import *\n",
    "    print(f\"Setup loaded. Using {AVAILABLE_PROVIDERS} with {get_default_model()}\")\n",
    "    print(\"Ready to continue.\")\n",
    "except ImportError:\n",
    "    print(\"Setup not found.\")\n",
    "    print(\"Please run module-01-fundamentals.ipynb first to set up your environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: Switch providers or configure direct APIs\n",
    "\n",
    "**Option 1: Configure via `.env` file (Recommended for persistent settings)**\n",
    "\n",
    "Add these lines to your `.env` file in the project root to set your default provider and model:\n",
    "\n",
    "```bash\n",
    "# Set default provider (options: openai, claude, circuit)\n",
    "MODULE2_PROVIDER=openai\n",
    "\n",
    "# Set default models for each provider\n",
    "MODULE2_OPENAI_MODEL=gpt-4o          # Options: gpt-5, gpt-4o, gpt-4o-mini\n",
    "MODULE2_CLAUDE_MODEL=claude-sonnet-4 # Options: claude-sonnet-4, claude-4\n",
    "MODULE2_CIRCUIT_MODEL=gpt-4.1        # Options: gpt-4.1, gpt-4o-mini\n",
    "```\n",
    "\n",
    "After updating `.env`, restart your notebook kernel and reload `setup_utils` to apply changes.\n",
    "\n",
    "**Option 2: Switch for this session only**\n",
    "\n",
    "- To switch for this session, run `set_provider(\"openai\")`, `set_provider(\"claude\")`, or `set_provider(\"circuit\")`.\n",
    "- To use direct OpenAI access, call `configure_openai_from_env()` after saving your API key to `.env`.\n",
    "- To use CircuIT (Cisco Azure OpenAI), call `configure_circuit_from_env()` and then `set_provider(\"circuit\")`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage (uncomment the line you need)\n",
    "# set_provider(\"openai\")\n",
    "# configure_openai_from_env()\n",
    "# configure_circuit_from_env(); set_provider(\"circuit\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Test Connection\n",
    "\n",
    "Test that everything is working before we begin.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"padding:12px; background:#fef3c7; border-radius:6px; border-left:4px solid #f59e0b; color:#78350f;\">\n",
    "<strong>üí° Tip:</strong><br><br>If you see long AI responses and the output shows \"Output is truncated. View as a scrollable element\" - <strong>click that link</strong> to see the full response in a scrollable view!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success, response = test_connection()\n",
    "\n",
    "if success:\n",
    "    print('Module 2 setup verified. Ready to continue.')\n",
    "else:\n",
    "    print('Connection responded unexpectedly. If you changed providers, double-check credentials above.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-top:16px; color:#15803d; padding:12px; background:#dcfce7; border-radius:6px; border-left:4px solid #22c55e;\">\n",
    "<style>\n",
    "code {\n",
    "  font-family: Consolas,\"courier new\";\n",
    "  color:rgb(238, 13, 13);\n",
    "  background-color: #f1f1f1;\n",
    "  padding: 2px;\n",
    "  font-size: 110%;\n",
    "}\n",
    "</style>\n",
    "<strong>üí° What's Available?</strong> <br><br>\n",
    "The <code>setup_utils.py</code> module provides these functions: <br><br>\n",
    "\n",
    "<strong>Core Functions:</strong>\n",
    "<ul>\n",
    "<li><code>get_chat_completion(messages)</code> - Send prompts to AI models</li>\n",
    "<li><code>get_default_model()</code> - Get current model name</li>\n",
    "<li><code>test_connection()</code> - Test AI connection</li>\n",
    "</ul>\n",
    "\n",
    "<strong>Provider Management:</strong>\n",
    "<ul>\n",
    "<li><code>AVAILABLE_PROVIDERS</code> - Tuple of available provider names</li>\n",
    "<li><code>get_provider()</code> - Get current active provider</li>\n",
    "<li><code>set_provider(name)</code> - Switch between providers (openai, claude, circuit)</li>\n",
    "<li><code>configure_openai_from_env()</code> - Configure direct OpenAI API</li>\n",
    "<li><code>configure_circuit_from_env()</code> - Configure CircuIT (Cisco Azure)</li>\n",
    "</ul>\n",
    "\n",
    "<strong>Evaluation & Progress Tracking:</strong>\n",
    "<ul>\n",
    "<li><code>evaluate_prompt(messages, activity_name, expected_tactics, ...)</code> - Get automated feedback using Traditional Metrics + Quality Assessment</li>\n",
    "<li><code>view_progress(activity_name)</code> - View evaluation history and track improvement over time</li>\n",
    "</ul>\n",
    "\n",
    "<strong>Parallel Execution (Advanced):</strong>\n",
    "<ul>\n",
    "<li><code>get_chat_completion_async(messages)</code> - Async version for parallel execution (used with asyncio.gather())</li>\n",
    "<li><code>run_async(coro)</code> - Run async code in Jupyter notebooks (handles event loop automatically)</li>\n",
    "</ul>\n",
    "<em>These are used in Section 2.4 for parallel exploration patterns.</em>\n",
    "\n",
    "These will be used throughout Module 2 to help you master the 6 core prompt engineering tactics!\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Complete!\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"background:#dcfce7; border-left:4px solid #22c55e; padding:20px; border-radius:8px; margin:24px 0; color:#000000;\">\n",
    "<style>\n",
    "code {\n",
    "  font-family: Consolas,\"courier new\";\n",
    "  color:rgb(238, 13, 13);\n",
    "  background-color: #f1f1f1;\n",
    "  padding: 2px;\n",
    "  font-size: 110%;\n",
    "}\n",
    "</style>\n",
    "<strong style=\"color:#166534;\">üéâ You're ready to go!</strong><br><br>\n",
    "You've installed dependencies, loaded shared helpers, and verified connectivity.\n",
    "<br><br>\n",
    "‚úÖ <strong style=\"color:#166534;\">AI connection</strong> responding as expected<br>\n",
    "‚úÖ <strong style=\"color:#166534;\">Shared utilities</strong> imported (<code>setup_utils.py</code>)<br>\n",
    "‚úÖ <strong style=\"color:#166534;\">Provider helpers</strong> ready for OpenAI, Claude, or CircuIT<br>\n",
    "‚úÖ <strong style=\"color:#166534;\">Breakpoints mapped</strong> so you can pause confidently<br>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Core Prompt Engineering Techniques\n",
    "\n",
    "### When Do These Techniques Actually Matter?\n",
    "\n",
    "If you use Claude Code, Cursor, or GitHub Copilot daily, these tools already handle much of this automatically to manage context, structure prompts, and organize information for you.\n",
    "\n",
    "**You need these techniques when:**\n",
    "\n",
    "**1. Debugging your tools**\n",
    "- Claude Code gives weird results? Knowing prompt structure helps diagnose why\n",
    "- Need to override default behavior for specialized tasks\n",
    "\n",
    "**2. Building custom integrations**\n",
    "- Calling LLMs directly (Circuit API, OpenAI, Anthropic)\n",
    "- Creating slash commands, bots, or CI/CD automation\n",
    "- Writing team workflows that need consistent results\n",
    "\n",
    "**3. Creating reusable templates**\n",
    "- Building code review automation or test generation systems\n",
    "- Designing prompts your team can use consistently\n",
    "\n",
    "**Think of it like autocomplete:** Your IDE does it automatically, but you still need to understand functions to write good code. Same here.\n",
    "\n",
    "---\n",
    "\n",
    "### Introduction\n",
    "\n",
    "You've set up your environment. Now you'll learn techniques that get consistent, reliable results from AI.\n",
    "\n",
    "#### What You're About to Master\n",
    "\n",
    "Before advanced techniques, master the fundamental: **writing clear instructions**. This is the foundation. Effective prompting requires clarity before sophistication.\n",
    "\n",
    "You'll learn **six core tactics**:\n",
    "\n",
    "<div style=\"display: grid; grid-template-columns: repeat(3, 1fr); gap: 16px; margin: 20px 0;\">\n",
    "\n",
    "<div style=\"background: #f8fafc; border: 2px solid #e2e8f0; border-radius: 8px; padding: 16px; text-align: center; color: #000000;\">\n",
    "<strong>üé≠ Role Prompting</strong><br>\n",
    "<em>Transform AI into specialized experts</em>\n",
    "</div>\n",
    "\n",
    "<div style=\"background: #f8fafc; border: 2px solid #e2e8f0; border-radius: 8px; padding: 16px; text-align: center; color: #000000;\">\n",
    "<strong>üìã Structured Inputs</strong><br>\n",
    "<em>Organize complex scenarios with precision</em>\n",
    "</div>\n",
    "\n",
    "<div style=\"background: #f8fafc; border: 2px solid #e2e8f0; border-radius: 8px; padding: 16px; text-align: center; color: #000000;\">\n",
    "<strong>üìö Few-Shot Examples</strong><br>\n",
    "<em>Teach AI your preferred style</em>\n",
    "</div>\n",
    "\n",
    "<div style=\"background: #f8fafc; border: 2px solid #e2e8f0; border-radius: 8px; padding: 16px; text-align: center; color: #000000;\">\n",
    "<strong>‚õìÔ∏è‚Äçüí• Chain-of-Thought</strong><br>\n",
    "<em>Guide AI through systematic reasoning</em>\n",
    "</div>\n",
    "\n",
    "<div style=\"background: #f8fafc; border: 2px solid #e2e8f0; border-radius: 8px; padding: 16px; text-align: center; color: #000000;\">\n",
    "<strong>üìñ Reference Citations</strong><br>\n",
    "<em>Answer with citations from reference text</em>\n",
    "</div>\n",
    "\n",
    "<div style=\"background: #f8fafc; border: 2px solid #e2e8f0; border-radius: 8px; padding: 16px; text-align: center; color: #000000;\">\n",
    "<strong>üîó Prompt Chaining</strong><br>\n",
    "<em>Break complex tasks into sequential steps</em>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"padding:12px; background:#dcfce7; border-radius:6px; border-left:4px solid #22c55e; color:#14532d;\">\n",
    "<strong>Tip:</strong> This module covers 6 tactics over 90-120 minutes. Take short breaks. Make notes on where each tactic applies to your projects.\n",
    "</div>\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tactic-0\"></a>\n",
    "### Tactic 0: Write Clear Instructions\n",
    "\n",
    "Clear instructions form the foundation for all other tactics. Here's what makes instructions effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Core Principle:** When interacting with AI models, think of them as brilliant but very new employees who need explicit instructions. The more precisely you explain what you want‚Äîincluding context, specific requirements, and sequential steps‚Äîthe better the AI's response will be.\n",
    "\n",
    "Show your prompt to a colleague with minimal context on the task. If they're confused, the AI will likely be too. This becomes crucial when asking for code refactoring, where you need to specify coding standards, performance requirements, and constraints to get production-ready results.\n",
    "\n",
    "*Reference: [Claude Documentation - Be Clear and Direct](https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/be-clear-and-direct)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Vague vs. Specific Instructions\n",
    "\n",
    "Specific instructions eliminate ambiguity and guide the model toward your exact requirements. Compare a generic approach with a specific one:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vague request - typical beginner mistake\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Help me choose a programming language for my project\"}\n",
    "]\n",
    "\n",
    "response = get_chat_completion(messages)\n",
    "\n",
    "print(\"VAGUE REQUEST RESULT:\")\n",
    "print(response)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific request - much better results\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"I need to choose a programming language for building a real-time chat application that will handle 10,000 concurrent users, needs to integrate with a PostgreSQL database, and must be deployable on AWS. The team has 3 years of experience with web development. Provide the top 3 language recommendations with pros and cons for each.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_chat_completion(messages)\n",
    "\n",
    "print(\"SPECIFIC REQUEST RESULT:\")\n",
    "print(response)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to achieve specificity is using the **system prompt**. The system prompt is a special message type in the conversation structure (alongside \"user\" and \"assistant\" messages) that sets overarching instructions, context, and behavioral guidelines for the AI before the user asks their question. Think of it as setting the \"rules of engagement\" for the entire conversation. It's particularly useful when you want to keep the user request clean while providing detailed instructions about response format, tone, constraints, and expertise level that should apply to all responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a senior technical architect. Provide concise, actionable recommendations in bullet format. Focus only on the most critical factors for the decision. No lengthy explanations.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Help me choose between microservices and monolithic architecture for a startup with 5 developers building a fintech application\",\n",
    "    },\n",
    "]\n",
    "\n",
    "response = get_chat_completion(messages)\n",
    "\n",
    "print(\"SYSTEM PROMPT RESULT:\")\n",
    "print(response)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding Message Structure\n",
    "\n",
    "<div style=\"margin-top:16px; color:#1e40af; padding:12px; background:#dbeafe; border-radius:6px; border-left:4px solid #3b82f6;\">\n",
    "<strong>üìù Note:</strong> Throughout this tutorial, we structure prompts as JSON with three message types:\n",
    "<ul style=\"margin: 8px 0;\">\n",
    "<li><strong>system:</strong> Sets overall instructions and behavior for the AI</li>\n",
    "<li><strong>user:</strong> Contains the actual question or task</li>\n",
    "<li><strong>assistant:</strong> Used for few-shot examples (you'll see this in Tactic 3)</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üéØ Try It Yourself: Clear Instructions\n",
    "\n",
    "**Common Misconception:** AI can understand vague requests and \"read your mind\" about what you need.\n",
    "\n",
    "**The Reality:** Specific instructions dramatically improve output quality.\n",
    "\n",
    "**Your Task:** Below is a vague prompt. Your job is to rewrite it with clear, specific instructions that include:\n",
    "- Context about the project\n",
    "- Specific requirements\n",
    "- Constraints or preferences\n",
    "- Expected output format\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"padding:12px; background:#dbeafe; border-radius:6px; border-left:4px solid #3b82f6; color:#1e40af;\">\n",
    "<strong>üìù Note:</strong><br><br>\n",
    "First, try creating your own improved prompt. Then run the evaluation cell below to compare your solution with best practices.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAD: Vague prompt\n",
    "bad_messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Help me optimize my database\"}\n",
    "]\n",
    "\n",
    "bad_response = get_chat_completion(bad_messages)\n",
    "print(\"=\" * 70)\n",
    "print(\"VAGUE PROMPT RESULT:\")\n",
    "print(\"=\" * 70)\n",
    "print(bad_response)\n",
    "print(\"\\n\")\n",
    "\n",
    "# YOUR TURN: Rewrite with specific instructions\n",
    "# TODO: Uncomment and complete this section\n",
    "# good_messages = [\n",
    "#     {\n",
    "#         \"role\": \"user\",\n",
    "#         \"content\": \"\"\"\n",
    "# I have a PostgreSQL database for an e-commerce site with 1 million products.\n",
    "# The product search query is taking 5+ seconds. Here's the current query:\n",
    "# \n",
    "# SELECT * FROM products WHERE name LIKE '%search_term%' OR description LIKE '%search_term%'\n",
    "# \n",
    "# Requirements:\n",
    "# - Reduce query time to under 1 second\n",
    "# - Must support partial text matching\n",
    "# - Can't change the database schema (production constraint)\n",
    "# - Provide top 3 optimization techniques\n",
    "# \n",
    "# Format response as:\n",
    "# 1. Technique name\n",
    "# 2. Implementation steps\n",
    "# 3. Expected performance improvement\n",
    "# \"\"\"\n",
    "#     }\n",
    "# ]\n",
    "# \n",
    "# good_response = get_chat_completion(good_messages)\n",
    "# print(\"=\" * 70)\n",
    "# print(\"SPECIFIC PROMPT RESULT:\")\n",
    "# print(\"=\" * 70)\n",
    "# print(good_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-top:12px; padding:24px; background:linear-gradient(120deg,#10b981 0%,#34d399 50%,#6ee7b7 100%); border-radius:14px; color:#064e3b; text-align:center; box-shadow:0 10px 24px rgba(16,185,129,0.25);\">\n",
    "  <strong style=\"display:block; font-size:1.15em; margin-bottom:6px;\">‚úÖ Great start! Ready to dive deeper?</strong>\n",
    "  <span style=\"font-size:0.98em; line-height:1.6;\">You've completed the setup and learned the foundation. Take a moment to stretch before continuing with the 6 core tactics.</span>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"margin:24px 0; padding:20px 24px; background:linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%); border-radius:12px; border-left:5px solid #3b82f6; box-shadow:0 2px 8px rgba(0,0,0,0.1);\">\n",
    "  <div style=\"color:#1e293b; font-size:0.85em; font-weight:600; text-transform:uppercase; letter-spacing:1px; margin-bottom:8px;\">‚è≠Ô∏è Next Section</div>\n",
    "  <div style=\"color:#0f172a; font-size:1.15em; font-weight:700; margin-bottom:6px;\">Section 2.2: Roles and Structure</div>\n",
    "  <div style=\"color:#475569; font-size:0.95em; line-height:1.5; margin-bottom:12px;\">Master role prompting personas and structured input patterns with XML delimiters.</div>\n",
    "  <a href=\"./2.2-roles-and-structure.ipynb\" style=\"display:inline-block; padding:8px 16px; background:#3b82f6; color:#fff; text-decoration:none; border-radius:6px; font-weight:600; font-size:0.9em; transition:all 0.2s;\">Continue to Section 2.2 ‚Üí</a>\n",
    "</div>\n",
    "\n",
    "\n",
    "> **üí° Tip:** The setup utilities are already loaded‚Äîjust run `from setup_utils import *` to continue."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
