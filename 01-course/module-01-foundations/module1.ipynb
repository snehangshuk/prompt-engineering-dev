{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1: Foundation\n",
    "\n",
    "| **Aspect** | **Details** |\n",
    "|-------------|-------------|\n",
    "| **Goal** | Set up your development environment and learn the 5 core elements of effective prompts |\n",
    "| **Time** | ~20 minutes |\n",
    "| **Prerequisites** | Python 3.8+, IDE with notebook support, API access (GitHub Copilot, CircuIT, or OpenAI) |\n",
    "| **Setup Required** | Clone the repository and follow [Quick Setup](../README.md) before running this notebook |\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Prompt Engineering for Software Engineers?\n",
    "\n",
    "<br>\n",
    "\n",
    "### What is Prompt Engineering?\n",
    "\n",
    "Prompt engineering is how you control LLM output. You give the model instructions, questions, or statements, and it adjusts its behavior to match what you need.\n",
    "\n",
    "**Benefits:**\n",
    "\n",
    "- Improve model accuracy and safety\n",
    "- Add domain knowledge and external tools without fine-tuning\n",
    "- Understand model capabilities through structured interaction\n",
    "- Get better results by writing better inputs\n",
    "\n",
    "<br>\n",
    "\n",
    "### Two Ways to Influence LLM Behavior\n",
    "\n",
    "**1. Fine-tuning (Traditional Approach)**\n",
    "- Adjusts model weights using training data\n",
    "- Expensive: requires significant compute time and cost\n",
    "- Limited flexibility: model locked into specific behavior patterns\n",
    "- Problem: Still produces vague, inconsistent results without proper context\n",
    "\n",
    "**2. Prompt Engineering vs. Context Engineering**\n",
    "\n",
    "According to [Anthropic's engineering team](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents), there's an important distinction:\n",
    "\n",
    "- **Prompt Engineering** refers to methods for writing and organizing LLM instructions for optimal outcomes\n",
    "- **Context Engineering** refers to the set of strategies for curating and maintaining the optimal set of information during LLM inference, including all the other information that may land there outside of the prompts\n",
    "\n",
    "**Key Difference:** Prompt engineering focuses on writing effective prompts, while context engineering manages the entire information available to the model (system instructions, tools, external data, message history, etc.) as a finite resource.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Understanding the Relationship\n",
    "\n",
    "| **Concept** | **What It Manages** | **Scope** | **Example** |\n",
    "|-------------|---------------------|-----------|-------------|\n",
    "| **Prompt Engineering** | Writing effective instructions | How you structure your questions and instructions | \"You are a security expert. Review this authentication code for vulnerabilities. Format response as: [Security Issues], [Fixes], [Priority]\" |\n",
    "| **Context Engineering** | Managing the entire context window | Everything the model sees: prompts + tools + external data + conversation history | Managing which information to include: current prompt + relevant code files + API documentation + conversation history + tool definitions + external data sources |\n",
    "| **Traditional Prompting** | Nothing - just asks vague questions | No structure or management | \"Fix this code\" |\n",
    "\n",
    "**This course focuses on Prompt Engineering** - writing instructions that produce consistent, high-quality results. Context Engineering is broader and applies when building production AI systems that manage large amounts of information.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Why Prompt Engineering Matters:**\n",
    "\n",
    "Poorly written prompts produce bad results, even with perfect context management. Prompt engineering teaches you to write clear, specific instructions that work whether you're chatting with an AI assistant or building a production system.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "**Traditional Prompting (‚ùå Vague):**\n",
    "```bash\n",
    "User: \"Fix this code\"\n",
    "\n",
    "AI: \"I'd be happy to help! Could you please share the code you'd like me to fix?\"\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "**Prompt Engineering (‚úÖ Structured Instructions):**\n",
    "```python\n",
    "User: \"You are a senior Python developer. Review this e-commerce checkout function. \n",
    "Requirements: Handle empty lists, add type hints, include error handling.\n",
    "\n",
    "def calculate_total(items): \n",
    "    return sum(items)\n",
    "\n",
    "Format response as: 1) Issues Found, 2) Fixed Code, 3) Tests\"\n",
    "\n",
    "AI: [Provides structured analysis with all requested sections]\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "**Context Engineering (Managing the Full Context):**\n",
    "```bash\n",
    "System manages all available information including:\n",
    "- Your prompt (above) \n",
    "- Relevant code files from the repository\n",
    "- API documentation\n",
    "- Previous conversation history\n",
    "- Available tools (code_analyzer, test_runner)\n",
    "- External data sources\n",
    "\n",
    "The model uses ALL of this to generate a response, but your PROMPT determines \n",
    "the quality and structure of that response.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "## Elements of a Prompt\n",
    "\n",
    "Prompts contain some or all of these five elements:\n",
    "\n",
    "### **1. Role (Persona)** \n",
    "\n",
    "Defining who the AI should act as shapes its expertise, perspective, and response quality.\n",
    "\n",
    "**Why it matters:**\n",
    "- Activates domain-specific knowledge (\"security expert\" prioritizes vulnerabilities)\n",
    "- Sets expertise level (junior dev vs. senior architect)\n",
    "- Changes perspective (code reviewer vs. performance optimizer)\n",
    "\n",
    "**What makes a strong role:**\n",
    "- Expertise level: senior, principal, experienced\n",
    "- Domain: Python developer, security engineer, DevOps specialist\n",
    "- Specialization: \"with expertise in async programming,\" \"specializing in authentication\"\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "| Weak | Strong |\n",
    "|------|--------|\n",
    "| \"You are a programmer\" | \"You are a senior Python developer specializing in async programming\" |\n",
    "| \"Review this code\" | \"You are a security engineer reviewing financial application code\" |\n",
    "| \"Help me debug\" | \"You are a principal engineer debugging distributed systems\" |\n",
    "\n",
    "**Impact:**\n",
    "\n",
    "*Without role:*\n",
    "```text\n",
    "User: \"Review this authentication code\"\n",
    "AI: \"The code looks okay, but you might want to add some error handling.\"\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "*With role:*\n",
    "```text\n",
    "User: \"You are a security engineer. Review this authentication code.\"\n",
    "AI: \"CRITICAL: Timing attack vulnerability. Use secrets.compare_digest() \n",
    "for password comparison. No rate limiting detected‚Äîvulnerable to brute force...\"\n",
    "```\n",
    "<br>\n",
    "Module 2 covers role prompting in depth (Tactic 1), including role switching and domain-specific personas.\n",
    "\n",
    "### **2. Instructions**\n",
    "The specific task for the AI to perform.\n",
    "\n",
    "**Example:** \"Analyze the provided code and identify potential security issues.\"\n",
    "\n",
    "### **3. Context**\n",
    "External information to guide the model.\n",
    "\n",
    "**Example:** \"Code context: This is a utility function for user registration in a web application.\"\n",
    "\n",
    "### **4. Input Data**\n",
    "The input for which you want a response.\n",
    "\n",
    "**Example:** \"Code to review: `def register_user(email, password): ...`\"\n",
    "\n",
    "### **5. Output Indicator**\n",
    "The output type or format.\n",
    "\n",
    "**Example:** \"Please provide your response in this format: 1) Security Issues, 2) Code Quality Issues, 3) Recommended Improvements, 4) Overall Assessment\"\n",
    "\n",
    "---\n",
    "\n",
    "## Evaluate and Iterate\n",
    "\n",
    "Review model responses and adjust prompts as needed. Prompt engineering is iterative‚Äîpractice builds intuition.\n",
    "\n",
    "**Tip:** Use one model instance to improve or check output from another.\n",
    "\n",
    "---\n",
    "\n",
    "## Getting Started: Setup and Practice\n",
    "\n",
    "Now that you understand why prompt engineering matters and what makes it effective, let's set up your development environment and start building! You'll create your first AI-powered code review assistant that demonstrates all the concepts we've covered.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How This Notebook Works\n",
    "\n",
    "<div style=\"margin-top:16px; color:#991b1b; padding:12px; background:#fee2e2; border-radius:6px; border-left:4px solid #ef4444;\">\n",
    "<strong>‚ö†Ô∏è Important:</strong> <br><br>\n",
    "This notebook cannot be executed directly from GitHub/GitLab. You must clone the repository and run it locally in your IDE.<br>\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-top:16px; color:#1e3a8a; padding:12px; background:#dbeafe; border-radius:6px; border-left:4px solid #3b82f6\">\n",
    "<strong>üÜï First time using Jupyter notebooks?</strong><br><br>\n",
    "See the <strong><a href=\"../../README.md#-about-jupyter-notebooks\">About Jupyter Notebooks</a></strong> section in the main README for a complete guide on how notebooks work, where code executes, and how to get started.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick start:**\n",
    "- Press `Shift + Enter` to run each cell\n",
    "- Run cells sequentially from top to bottom\n",
    "- Output appears below each cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Install Required Dependencies\n",
    "\n",
    "Install the required packages. Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    subprocess.run(\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\"],\n",
    "        check=True\n",
    "    )\n",
    "    print(\"\\nSUCCESS: All dependencies installed.\")\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"\\nInstallation failed.\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"   1. Ensure pip is installed: python -m ensurepip --upgrade\")\n",
    "    print(\"   2. Try manual install: pip install openai anthropic python-dotenv requests\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError: {e}\")\n",
    "    print(\"Try manual install: pip install openai anthropic python-dotenv requests\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Connect to AI Model\n",
    "\n",
    "<div style=\"margin-top:16px; color:#78350f; padding:12px; background:#fef3c7; border-radius:6px; border-left:4px solid #f59e0b;\">\n",
    "<strong>üí° Note:</strong> <br><br>\n",
    "The code below runs on your local machine and connects to AI services over the internet.\n",
    "</div>\n",
    "\n",
    "Choose your preferred option below. Each option has detailed setup instructions in its own section:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option A: GitHub Copilot (Recommended)\n",
    "\n",
    "**Best for:** Users with GitHub Copilot subscription (no additional API keys needed)\n",
    "\n",
    "**Supports:** Both Claude and OpenAI models\n",
    "\n",
    "**Setup:**\n",
    "1. Follow the setup steps in the [copilot-api README](https://cd.splunkdev.com/eng-enablement/copilot-api/-/blob/0f706b342ac44863c2fb138854f90e659af130de/.github/README.md) to authenticate (`auth`) with your GitHub account that has Copilot access\n",
    "2. Start the local server (default: `http://localhost:7711`)\n",
    "3. Run the \"GitHub Copilot API setup\" cell below\n",
    "\n",
    "**Quick reference** (see [README](../../GitHub-Copilot-2-API/README.md) for details):\n",
    "\n",
    "> **‚ö†Ô∏è Splunk Users - Artifactory Setup Required**: Run `okta-artifactory-login -t pypi` **before** the setup steps below. Without this, pip install will fail. See [Artifactory PyPI setup guide](https://cloud-automation.splunkdev.page/ci-cd/artifactory/ephemeral-credentials-examples/user-guide/pypi/) for installation instructions.\n",
    "\n",
    "1. **Download and install dependencies**\n",
    "    ```bash\n",
    "    git clone git@cd.splunkdev.com:eng-enablement/copilot-api.git\n",
    "    cd copilot-api\n",
    "    python3 -m venv .venv\n",
    "    source .venv/bin/activate\n",
    "    pip install --upgrade setuptools wheel\n",
    "    pip install -e .\n",
    "\n",
    "    # Alternative: uv sync\n",
    "    ```\n",
    "\n",
    "2. **Authenticate with GitHub**\n",
    "    ```bash\n",
    "    copilot2api auth --business\n",
    "    # Alternative: uv run copilot2api auth --business\n",
    "    ```\n",
    "    \n",
    "    When authenticating, you'll see a device code. Open `https://github.com/login/device` in your browser, log in with your GitHub account (must have Copilot access), and enter the code shown in the terminal. **Don't copy the code from the terminal**‚Äîenter it in the browser.\n",
    "    \n",
    "    After successful authorization:\n",
    "    - macOS/Linux: Token saved to `$HOME/.config/copilot2api/github-token`\n",
    "    - Windows: Token saved to `C:\\Users\\<username>\\AppData\\Roaming\\copilot2api\\github-token`\n",
    "\n",
    "3. **Start the Server**\n",
    "    ```bash\n",
    "    copilot2api start\n",
    "    # Alternative: uv run copilot2api start\n",
    "    ```\n",
    "\n",
    "Run the cell below to connect to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: GitHub Copilot API setup (Recommended)\n",
    "import openai\n",
    "import anthropic\n",
    "import os\n",
    "\n",
    "# ============================================\n",
    "# CHOOSE YOUR AI MODEL PROVIDER\n",
    "# ============================================\n",
    "# Set your preference: \"openai\" or \"claude\"\n",
    "PROVIDER = \"claude\"  # Change to \"claude\" to use Claude models\n",
    "\n",
    "# ============================================\n",
    "# Available Models by Provider\n",
    "# ============================================\n",
    "# OpenAI Models (via GitHub Copilot):\n",
    "#   - gpt-4o (recommended)\n",
    "#   - gpt-4\n",
    "#   - gpt-3.5-turbo\n",
    "#   - o3-mini, o4-mini\n",
    "#\n",
    "# Claude Models (via GitHub Copilot):\n",
    "#   - claude-sonnet-4 (recommended)\n",
    "#   - claude-4 \n",
    "# ============================================\n",
    "\n",
    "# Configure clients for both providers\n",
    "openai_client = openai.OpenAI(\n",
    "    base_url=\"http://localhost:7711/v1\",\n",
    "    api_key=\"dummy-key\"\n",
    ")\n",
    "\n",
    "claude_client = anthropic.Anthropic(\n",
    "    api_key=\"dummy-key\",\n",
    "    base_url=\"http://localhost:7711\"\n",
    ")\n",
    "\n",
    "# Set default models for each provider\n",
    "OPENAI_DEFAULT_MODEL = \"gpt-4o\"\n",
    "CLAUDE_DEFAULT_MODEL = \"claude-sonnet-4\"\n",
    "\n",
    "\n",
    "def _extract_text_from_blocks(blocks):\n",
    "    \"\"\"Extract text content from response blocks returned by the API.\"\"\"\n",
    "    parts = []\n",
    "    for block in blocks:\n",
    "        text_val = getattr(block, \"text\", None)\n",
    "        if isinstance(text_val, str):\n",
    "            parts.append(text_val)\n",
    "        elif isinstance(block, dict):\n",
    "            t = block.get(\"text\")\n",
    "            if isinstance(t, str):\n",
    "                parts.append(t)\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "\n",
    "def get_openai_completion(messages, model=None, temperature=0.0):\n",
    "    \"\"\"Get completion from OpenAI models via GitHub Copilot.\"\"\"\n",
    "    if model is None:\n",
    "        model = OPENAI_DEFAULT_MODEL\n",
    "    try:\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error: {e}\\nüí° Make sure GitHub Copilot proxy is running on port 7711\"\n",
    "\n",
    "\n",
    "def get_claude_completion(messages, model=None, temperature=0.0):\n",
    "    \"\"\"Get completion from Claude models via GitHub Copilot.\"\"\"\n",
    "    if model is None:\n",
    "        model = CLAUDE_DEFAULT_MODEL\n",
    "    try:\n",
    "        response = claude_client.messages.create(\n",
    "            model=model,\n",
    "            max_tokens=8192,\n",
    "            messages=messages,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        return _extract_text_from_blocks(getattr(response, \"content\", []))\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error: {e}\\nüí° Make sure GitHub Copilot proxy is running on port 7711\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_chat_completion(messages, model=None, temperature=0.0):\n",
    "    \"\"\"\n",
    "    Generic function to get chat completion from any provider.\n",
    "    Routes to the appropriate provider-specific function based on PROVIDER setting.\n",
    "    \"\"\"\n",
    "    if PROVIDER.lower() == \"claude\":\n",
    "        return get_claude_completion(messages, model, temperature)\n",
    "    else:  # Default to OpenAI\n",
    "        return get_openai_completion(messages, model, temperature)\n",
    "\n",
    "\n",
    "def get_default_model():\n",
    "    \"\"\"Get the default model for the current provider.\"\"\"\n",
    "    if PROVIDER.lower() == \"claude\":\n",
    "        return CLAUDE_DEFAULT_MODEL\n",
    "    else:\n",
    "        return OPENAI_DEFAULT_MODEL\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# TEST CONNECTION\n",
    "# ============================================\n",
    "print(\"Testing connection to GitHub Copilot proxy...\")\n",
    "test_result = get_chat_completion([\n",
    "    {\"role\": \"user\", \"content\": \"test\"}\n",
    "])\n",
    "\n",
    "if test_result and \"Error\" in test_result:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CONNECTION FAILED\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Provider: {PROVIDER.upper()}\")\n",
    "    print(f\"Expected endpoint: http://localhost:7711\")\n",
    "    print(\"\\nThe GitHub Copilot proxy is not running.\")\n",
    "    print(\"\\nTo fix:\")\n",
    "    print(\"   1. Open a new terminal\")\n",
    "    print(\"   2. Navigate to your copilot-api directory\")\n",
    "    print(\"   3. Run: uv run copilot2api start\")\n",
    "    print(\"   4. Wait for 'Server initialized' message\")\n",
    "    print(\"   5. Rerun this cell\")\n",
    "    print(\"\\nSetup help: GitHub-Copilot-2-API/README.md\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CONNECTION SUCCESSFUL\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Provider: {PROVIDER.upper()}\")\n",
    "    print(f\"Default Model: {get_default_model()}\")\n",
    "    print(f\"Endpoint: http://localhost:7711\")\n",
    "    print(f\"\\nTo switch providers, change PROVIDER and rerun this cell\")\n",
    "    print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Option B: OpenAI API\n",
    "\n",
    "**Best for:** Users with direct OpenAI API access\n",
    "\n",
    "**Setup:** Add your API key to `.env` file, then uncomment and run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Direct OpenAI API setup\n",
    "# import openai\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# client = openai.OpenAI(\n",
    "#     api_key=os.getenv(\"OPENAI_API_KEY\")  # Set this in your .env file\n",
    "# )\n",
    "\n",
    "# def get_chat_completion(messages, model=\"gpt-4\", temperature=0.7):\n",
    "#     try:\n",
    "#         response = client.chat.completions.create(\n",
    "#             model=model,\n",
    "#             messages=messages,\n",
    "#             temperature=temperature\n",
    "#         )\n",
    "#         return response.choices[0].message.content\n",
    "#     except Exception as e:\n",
    "#         return f\"Error: {e}\"\n",
    "\n",
    "# print(\"OpenAI API configured successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option C: CircuIT APIs\n",
    "\n",
    "**Best for:** Cisco employees with CircuIT API access\n",
    "\n",
    "**Setup:** Configure environment variables (`CISCO_CLIENT_ID`, `CISCO_CLIENT_SECRET`, `CISCO_OPENAI_APP_KEY`) in `.env` file.\n",
    "\n",
    "Get values from: https://ai-chat.cisco.com/bridgeit-platform/api/home\n",
    "\n",
    "Then uncomment and run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import base64\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# from openai import AzureOpenAI\n",
    "\n",
    "# # Load environment variables\n",
    "# load_dotenv()\n",
    "\n",
    "# # Get API_KEY wrapped in token - using environment variables\n",
    "# client_id = os.getenv(\"CISCO_CLIENT_ID\")\n",
    "# client_secret = os.getenv(\"CISCO_CLIENT_SECRET\")\n",
    "\n",
    "# url = \"https://id.cisco.com/oauth2/default/v1/token\"\n",
    "\n",
    "# payload = \"grant_type=client_credentials\"\n",
    "# value = base64.b64encode(f\"{client_id}:{client_secret}\".encode(\"utf-8\")).decode(\"utf-8\")\n",
    "# headers = {\n",
    "#     \"Accept\": \"*/*\",\n",
    "#     \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "#     \"Authorization\": f\"Basic {value}\",\n",
    "# }\n",
    "\n",
    "# token_response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "# print(token_response.text)\n",
    "# token_data = token_response.json()\n",
    "\n",
    "# client = AzureOpenAI(\n",
    "#     azure_endpoint=\"https://chat-ai.cisco.com\",\n",
    "#     api_key=token_data.get(\"access_token\"),\n",
    "#     api_version=\"2024-12-01-preview\",\n",
    "# )\n",
    "\n",
    "# app_key = os.getenv(\"CISCO_OPENAI_APP_KEY\")\n",
    "\n",
    "# def get_chat_completion(messages, model=\"gpt-4.1\", temperature=0.0):\n",
    "#     try:\n",
    "#         response = client.chat.completions.create(\n",
    "#             model=model,\n",
    "#             messages=messages,\n",
    "#             temperature=temperature,\n",
    "#             user=f'{\"appkey\": \"{app_key}\"}',\n",
    "#         )\n",
    "#         return response.choices[0].message.content\n",
    "#     except Exception as e:\n",
    "#         return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Test Connection\n",
    "\n",
    "**Understanding Message Roles:**\n",
    "\n",
    "AI models use a conversation format with different message types:\n",
    "\n",
    "- `\"role\": \"system\"` ‚Äî Sets instructions and behavior (e.g., \"You are a helpful assistant\")\n",
    "- `\"role\": \"user\"` ‚Äî Your question or request\n",
    "- `\"role\": \"assistant\"` ‚Äî The AI's responses (used for examples, covered in Module 2)\n",
    "\n",
    "**Simple breakdown:**\n",
    "- **System** = Rules for the conversation\n",
    "- **User** = What you're asking for\n",
    "\n",
    "Run the cell below to test your connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the connection with a simple prompt\n",
    "test_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful coding assistant. Respond with exactly: 'Connection successful! Ready for prompt engineering.'\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Test the connection\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_chat_completion(test_messages)\n",
    "print(\"Test Response:\")\n",
    "print(response)\n",
    "\n",
    "if response and \"Connection successful\" in response:\n",
    "    print(\"\\nConnection verified. Ready to continue.\")\n",
    "else:\n",
    "    print(\"\\nConnection test complete. Response format may vary‚Äîthis is normal.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connection verified. Ready to continue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Craft Your First AI-Powered Code Review\n",
    "\n",
    "Let's see the 5 core elements in action with a software engineering example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Code review prompt with all 5 elements\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"\n",
    "            You are a senior software engineer with expertise in code reviews.\n",
    "            Analyze the provided code and identify potential issues.\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"\n",
    "Code context: This is a utility function for user registration in a web application.\n",
    "\n",
    "Code to review:\n",
    "```\n",
    "def register_user(email, password):\n",
    "    if email and password:\n",
    "        user = {\"email\": email, \"password\": password}\n",
    "        return user\n",
    "    return None\n",
    "```\n",
    "\n",
    "Please provide your response in this format:\n",
    "1. Security Issues (if any)\n",
    "2. Code Quality Issues (if any)  \n",
    "3. Recommended Improvements\n",
    "4. Overall Assessment\n",
    "\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_chat_completion(messages)\n",
    "print(\"CODE REVIEW RESULT:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-On Practice\n",
    "\n",
    "Now let's practice what you've learned!\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"padding:12px; background:#dcfce7; border-radius:6px; border-left:4px solid #22c55e; color:#14532d;\">\n",
    "<strong>‚≠ê How This Works</strong><br><br>\n",
    "Work through each activity independently. After completing your solution, compare it with the suggested approach in the solutions section below.\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "**In this section you will:**\n",
    "- Identify missing elements in incomplete prompts\n",
    "- Build complete prompts from scratch\n",
    "- Apply the 5 core elements to real coding scenarios\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Activity 1.1: Analyze Prompts and Identify Missing Elements\n",
    "\n",
    "**Goal:** Identify which of the 5 core elements are missing from incomplete prompts.\n",
    "\n",
    "**Your Task:** For each prompt below, determine which elements (Role, Instructions, Context, Input Data, Output Format) are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt 1\n",
    "prompt_1 = \"\"\"\n",
    "Fix this code:\n",
    "def calculate(x, y):\n",
    "    return x + y\n",
    "\"\"\"\n",
    "\n",
    "# Prompt 2\n",
    "prompt_2 = \"\"\"\n",
    "You are a Python developer.\n",
    "Make this function better.\n",
    "\"\"\"\n",
    "\n",
    "# Prompt 3\n",
    "prompt_3 = \"\"\"\n",
    "Review the following function and provide feedback.\n",
    "Return your response as a list of improvements.\n",
    "\"\"\"\n",
    "\n",
    "# YOUR ANALYSIS: Write your notes identifying which elements are missing\n",
    "# Prompt 1 missing: _______________\n",
    "# Prompt 2 missing: _______________\n",
    "# Prompt 3 missing: _______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity 1.2: Create a Complete Prompt with All 5 Elements\n",
    "\n",
    "**Goal:** Build a complete prompt that includes all 5 core elements to generate documentation for the function below.\n",
    "\n",
    "<div style=\"padding:12px; background:#dbeafe; border-radius:6px; border-left:4px solid #3b82f6; color:#1e40af;\">\n",
    "<strong>üìù Success Criteria:</strong><br><br>\n",
    "Your solution should have:\n",
    "<ul>\n",
    "<li>System message with clear role and instructions</li>\n",
    "<li>User message with context about the function</li>\n",
    "<li>The function code as input data</li>\n",
    "<li>A specified output format (e.g., Purpose, Parameters, Return Value, etc.)</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_to_document = \"\"\"\n",
    "def process_transaction(user_id, amount, transaction_type):\n",
    "    if transaction_type not in ['deposit', 'withdrawal']:\n",
    "        raise ValueError(\"Invalid transaction type\")\n",
    "    \n",
    "    if amount <= 0:\n",
    "        raise ValueError(\"Amount must be positive\")\n",
    "    \n",
    "    balance = get_user_balance(user_id)\n",
    "    \n",
    "    if transaction_type == 'withdrawal' and balance < amount:\n",
    "        raise InsufficientFundsError(\"Insufficient funds\")\n",
    "    \n",
    "    new_balance = balance + amount if transaction_type == 'deposit' else balance - amount\n",
    "    update_user_balance(user_id, new_balance)\n",
    "    log_transaction(user_id, amount, transaction_type)\n",
    "    \n",
    "    return new_balance\n",
    "\"\"\"\n",
    "\n",
    "# YOUR SOLUTION: Build complete prompt with all 5 elements\n",
    "# TODO: Uncomment and complete\n",
    "\n",
    "# messages = [\n",
    "#     {\n",
    "#         \"role\": \"system\",\n",
    "#         \"content\": f\"\"\"\n",
    "#         # TODO: Write the role and instructions here\n",
    "# \"\"\"      \n",
    "#     },\n",
    "#     {\n",
    "#         \"role\": \"user\",\n",
    "#         \"content\": f\"\"\"\n",
    "# TODO: Write the context, input data, and output format here\n",
    "# Context: ...\n",
    "#\n",
    "# Function to document:\n",
    "# {function_to_document}\n",
    "#\n",
    "# Output format:\n",
    "# 1. ...\n",
    "# 2. ...\n",
    "# \"\"\"\n",
    "#     }\n",
    "# ]\n",
    "#\n",
    "# response = get_chat_completion(messages)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity Solutions\n",
    "\n",
    "<div style=\"padding:12px; background:#fef3c7; border-radius:6px; border-left:4px solid #f59e0b; color:#78350f;\">\n",
    "<strong>üí° Try the exercises first!</strong><br><br>\n",
    "Complete Activities 1.1 and 1.2 before reviewing the solutions below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Activity 1.1 Solution\n",
    "\n",
    "**Prompt 1 Analysis:**\n",
    "```\n",
    "\"Fix this code: def calculate(x, y): return x + y\"\n",
    "```\n",
    "**Missing elements:**\n",
    "- **Role** - No role definition (who should do this?)\n",
    "- **Instructions** - No clear task specified beyond \"fix\"\n",
    "- **Context** - What is this function supposed to do? What's wrong with it?\n",
    "- **Input Data** - Has the code ‚úì\n",
    "- **Output Format** - No specification for how the fixed code should be presented\n",
    "\n",
    "**Prompt 2 Analysis:**\n",
    "```\n",
    "\"You are a Python developer. Make this function better.\"\n",
    "```\n",
    "**Missing elements:**\n",
    "- **Role** - Has a role (\"Python developer\") ‚úì\n",
    "- **Instructions** - \"Better\" is vague, no specific task\n",
    "- **Context** - What function? What makes it need improvement?\n",
    "- **Input Data** - No function provided\n",
    "- **Output Format** - No format specified\n",
    "\n",
    "**Prompt 3 Analysis:**\n",
    "```\n",
    "\"Review the following function and provide feedback. Return your response as a list of improvements.\"\n",
    "```\n",
    "**Missing elements:**\n",
    "- **Role** - No role definition (who should review it?)\n",
    "- **Instructions** - Has instructions (\"review and provide feedback\") ‚úì\n",
    "- **Context** - What's the function's purpose? What domain?\n",
    "- **Input Data** - Says \"following function\" but none is provided\n",
    "- **Output Format** - Has format (\"list of improvements\") ‚úì\n",
    "\n",
    "---\n",
    "\n",
    "### Activity 1.2 Solution\n",
    "\n",
    "Here's a complete prompt with all 5 elements clearly separated:\n",
    "\n",
    "```python\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            # ROLE: Who the AI should act as\n",
    "            \"You are a senior software engineer with expertise in financial systems. \"\n",
    "            \n",
    "            # INSTRUCTIONS: What task to perform\n",
    "            \"Create clear, comprehensive technical documentation for Python functions.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"\n",
    "# CONTEXT: Background information\n",
    "This is a financial transaction processing function for a banking application. It handles deposits and withdrawals with validation and error handling.\n",
    "\n",
    "# INPUT DATA: The function to document\n",
    "{function_to_document}\n",
    "\n",
    "# OUTPUT FORMAT: Expected structure\n",
    "Please provide documentation in this format:\n",
    "1. Function Purpose\n",
    "2. Parameters (name, type, description for each)\n",
    "3. Return Value\n",
    "4. Exceptions/Error Conditions\n",
    "5. Usage Example\n",
    "\"\"\"\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "**Why this works - all 5 elements present:**\n",
    "- **Role** - \"senior software engineer with expertise in financial systems\" ‚úì\n",
    "- **Instructions** - \"Create clear, comprehensive technical documentation\" ‚úì\n",
    "- **Context** - \"financial transaction processing function for a banking application\" ‚úì\n",
    "- **Input Data** - The complete function code ‚úì\n",
    "- **Output Format** - Numbered list with specific sections ‚úì\n",
    "\n",
    "**Key takeaway:** Separating role (WHO) from instructions (WHAT) creates clearer, more effective prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<div style=\"padding:16px; background:linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius:10px; color:#fff; text-align:center; box-shadow:0 4px 15px rgba(102,126,234,0.3);\">\n",
    "  <strong style=\"font-size:1.05em;\">üéâ Excellent work completing the hands-on activities!</strong><br>\n",
    "  <span style=\"font-size:0.92em; opacity:0.95; margin-top:4px; display:block;\">You've practiced identifying missing elements and building complete prompts.</span>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "**You've now completed:**\n",
    "- ‚úÖ Analyzed incomplete prompts to identify missing elements\n",
    "- ‚úÖ Created complete prompts with all 5 core elements\n",
    "- ‚úÖ Applied prompt engineering to real coding scenarios\n",
    "\n",
    "<br>\n",
    "\n",
    "**What makes effective prompts work:**\n",
    "- Clear role definition guides the AI's perspective and expertise\n",
    "- Specific instructions tell the AI exactly what task to perform\n",
    "- Relevant context provides domain knowledge the AI needs\n",
    "- Concrete input gives the AI something tangible to work with\n",
    "- Structured output format ensures consistent, actionable results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 1 Complete\n",
    "\n",
    "<div style=\"padding:12px; background:#dcfce7; border-radius:6px; border-left:4px solid #22c55e; color:#14532d;\">\n",
    "<strong>‚úÖ Progress Check</strong\n",
    "You've learned the foundations of prompt engineering and practiced applying the 5 core elements to real coding scenarios.\n",
    "</div>\n",
    "\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Role** - Define who the AI should act as\n",
    "2. **Instructions** - Specify the task to perform\n",
    "3. **Context** - Provide background information\n",
    "4. **Input Data** - Give specific content to work with\n",
    "5. **Output Format** - Specify structure of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div style=\"padding:20px 24px; background:linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%); border-radius:12px; border-left:5px solid #3b82f6; box-shadow:0 2px 8px rgba(0,0,0,0.1);\">\n",
    "  <div style=\"color:#1e293b; font-size:0.85em; font-weight:600; text-transform:uppercase; letter-spacing:1px; margin-bottom:8px;\">‚è≠Ô∏è Next Steps</div>\n",
    "  <div style=\"color:#0f172a; font-size:1.15em; font-weight:700; margin-bottom:6px;\">Module 2: Core Prompting Techniques</div>\n",
    "  <div style=\"color:#475569; font-size:0.95em; line-height:1.5; margin-bottom:12px;\">Master 7 practical techniques used by professional developers to get consistently excellent results from AI assistants.</div>\n",
    "  <div style=\"color:#475569; font-size:0.9em; line-height:1.6; margin-bottom:14px;\">\n",
    "    <strong>You'll learn:</strong><br>\n",
    "    ‚Ä¢ Clear, specific instructions that eliminate ambiguity<br>\n",
    "    ‚Ä¢ Role prompting to transform AI into specialized expert<br>\n",
    "    ‚Ä¢ XML-structured inputs to organize complex information<br>\n",
    "    ‚Ä¢ Few-shot examples to teach AI your coding style<br>\n",
    "    ‚Ä¢ Chain-of-thought reasoning for systematic analysis<br>\n",
    "    ‚Ä¢ Reference citations to prevent hallucination<br>\n",
    "    ‚Ä¢ Prompt chaining for multi-step workflow<br>\n",
    "    ‚Ä¢ Decision support to explore alternatives before committing<br>\n",
    "  </div>\n",
    "  <a href=\"../module-02-fundamentals/README.md\" style=\"display:inline-block; padding:8px 16px; background:#3b82f6; color:#fff; text-decoration:none; border-radius:6px; font-weight:600; font-size:0.9em; transition:all 0.2s;\">Continue to Module 2 ‚Üí</a>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
